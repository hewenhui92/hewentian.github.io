<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Tim Ho&#39;s Technology Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="my personal blog">
<meta property="og:type" content="website">
<meta property="og:title" content="Tim Ho&#39;s Technology Blog">
<meta property="og:url" content="https://github.com/hewentian/index.html">
<meta property="og:site_name" content="Tim Ho&#39;s Technology Blog">
<meta property="og:description" content="my personal blog">
<meta property="og:locale" content="en-US">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tim Ho&#39;s Technology Blog">
<meta name="twitter:description" content="my personal blog">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Tim Ho&#39;s Technology Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">心如止水</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives/">Archives</a>
        
          <a class="main-nav-link" href="/categories/">Categories</a>
        
          <a class="main-nav-link" href="/tags/">Tags</a>
        
          <a class="main-nav-link" href="/about/">About</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://github.com/hewentian"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-jenkins-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/05/jenkins-install/" class="article-date">
  <time datetime="2018-10-05T04:02:47.000Z" itemprop="datePublished">2018-10-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/other/">other</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/05/jenkins-install/">jenkins 学习笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本篇将说说jenkins的使用。</p>
<p>首先，我们要将<code>jenkins</code>的安装包下载回来，可以在它的<a href="http://mirrors.jenkins.io/war-stable/latest/" target="_blank" rel="noopener">官网</a>下载最新稳定版：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/</span><br><span class="line">$ wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war</span><br><span class="line">$ wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war.sha256</span><br><span class="line"></span><br><span class="line">验证下载文件的完整性</span><br><span class="line">$ sha256sum -c jenkins.war.sha256 </span><br><span class="line">jenkins.war: OK</span><br></pre></td></tr></table></figure>
<p>我们将它安装在当前目录(<code>/home/hewentian/ProjectD</code>)下，在当前目录下创建一个jenkins目录，用作<code>JENKINS_HOME</code>目录，我们将相关命令放到一个脚本<code>start_jenkins.sh</code>中：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD</span><br><span class="line">$ touch start_jenkins.sh</span><br><span class="line">$ vi start_jenkins.sh</span><br></pre></td></tr></table></figure></p>
<p>其中<code>start_jenkins.sh</code>脚本的内容如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">JENKINS_HOME=/home/hewentian/ProjectD/jenkins</span><br><span class="line">JENKINS_WAR=/home/hewentian/ProjectD/jenkins.war</span><br><span class="line">LOG_ROOT=<span class="variable">$JENKINS_HOME</span>/logs</span><br><span class="line">LOG_FILE=<span class="variable">$LOG_ROOT</span>/jenkins.log</span><br><span class="line">WEB_ROOT=<span class="variable">$JENKINS_HOME</span>/war</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Starting Jenkins ..."</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"JENKINS_HOME: <span class="variable">$JENKINS_HOME</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"JENKINS_WAR: <span class="variable">$JENKINS_WAR</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"LOG_FILE: <span class="variable">$LOG_FILE</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"WEB_ROOT: <span class="variable">$WEB_ROOT</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="variable">$JENKINS_HOME</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"creating: <span class="variable">$JENKINS_HOME</span>"</span></span><br><span class="line">    mkdir <span class="variable">$JENKINS_HOME</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="variable">$LOG_ROOT</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"creating: <span class="variable">$LOG_ROOT</span>"</span></span><br><span class="line">    mkdir <span class="variable">$LOG_ROOT</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -e <span class="variable">$LOG_FILE</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"creating: <span class="variable">$LOG_FILE</span>"</span></span><br><span class="line">    touch <span class="variable">$LOG_FILE</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="variable">$WEB_ROOT</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"creating: <span class="variable">$WEB_ROOT</span>"</span></span><br><span class="line">    mkdir <span class="variable">$WEB_ROOT</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">java -Xms1024m -Xmx1024m -Djava.awt.headless=<span class="literal">true</span> -DJENKINS_HOME=<span class="variable">$JENKINS_HOME</span> -jar <span class="variable">$JENKINS_WAR</span> --logfile=<span class="variable">$LOG_FILE</span> --webroot=<span class="variable">$WEB_ROOT</span> --httpPort=8080 --daemon &gt;&gt; <span class="variable">$LOG_FILE</span></span><br><span class="line"></span><br><span class="line">tail -f <span class="variable">$LOG_FILE</span></span><br></pre></td></tr></table></figure></p>
<p>启动jenkins：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ chmod +x start_jenkins.sh</span><br><span class="line">$ . start_jenkins.sh</span><br></pre></td></tr></table></figure></p>
<p>如果你看到如下输出：</p>
<pre><code>Starting Jenkins ...
JENKINS_HOME: /home/hewentian/ProjectD/jenkins
JENKINS_WAR: /home/hewentian/ProjectD/jenkins.war
LOG_FILE: /home/hewentian/ProjectD/jenkins/logs/jenkins.log
WEB_ROOT: /home/hewentian/ProjectD/jenkins/war
creating: /home/hewentian/ProjectD/jenkins
creating: /home/hewentian/ProjectD/jenkins/logs
creating: /home/hewentian/ProjectD/jenkins/logs/jenkins.log
creating: /home/hewentian/ProjectD/jenkins/war
Forking into background to run as a daemon.
Running from: /home/hewentian/ProjectD/jenkins.war
Oct 06, 2018 10:48:18 AM org.eclipse.jetty.util.log.Log initialized
INFO: Logging initialized @780ms to org.eclipse.jetty.util.log.JavaUtilLog
Oct 06, 2018 10:48:18 AM winstone.Logger logInternal
.
.
. 中间省略部分日志
.
Oct 06, 2018 10:48:29 AM jenkins.install.SetupWizard init
INFO: 

*************************************************************
*************************************************************
*************************************************************

Jenkins initial setup is required. An admin user has been created and a password generated.
Please use the following password to proceed to installation:

02b24053bc4844f4a348fdbbbf65c347

This may also be found at: /home/hewentian/ProjectD/jenkins/secrets/initialAdminPassword

*************************************************************
*************************************************************
*************************************************************

Oct 06, 2018 10:48:36 AM hudson.model.UpdateSite updateData
INFO: Obtained the latest update center data file for UpdateSource default
Oct 06, 2018 10:48:37 AM hudson.model.UpdateSite updateData
INFO: Obtained the latest update center data file for UpdateSource default
Oct 06, 2018 10:48:37 AM jenkins.InitReactorRunner$1 onAttained
INFO: Completed initialization
Oct 06, 2018 10:48:37 AM hudson.WebAppMain$3 run
INFO: Jenkins is fully up and running
Oct 06, 2018 10:48:37 AM hudson.model.DownloadService$Downloadable load
INFO: Obtained the updated data file for hudson.tasks.Maven.MavenInstaller
Oct 06, 2018 10:48:37 AM hudson.model.AsyncPeriodicWork$1 run
INFO: Finished Download metadata. 10,126 ms
</code></pre><p>则证明启动成功，我们按上面的提示打开浏览器，输入：<br><a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a></p>
<p>你将会见到如下界面：<br><img src="/img/jenkins-1.png" alt="" title="jenkins初次启动界面"></p>
<p>将上面日志中的密码输入到上述界面，并点击<code>[Continue]</code>按钮，将出现下图界面：<br><img src="/img/jenkins-2.png" alt="" title="jenkins安装插件界面"></p>
<p>为简单起见，选择<code>Install suggested plugins</code>安装即可，安装进度如下：<br><img src="/img/jenkins-3.png" alt="" title="jenkins安装插件界面"></p>
<p>接下来是设置admin用户和密码：<br>Username: hewentian<br>Password: abc123</p>
<p><img src="/img/jenkins-4.png" alt="" title="jenkins设置admin用户"></p>
<p>点击<code>[Save and Continue]</code>，并在接下来的界面点击<code>[Save and Finish]</code>完成设置。<br><img src="/img/jenkins-5.png" alt="" title="jenkins最终界面"></p>
<h3 id="下面进行简单的配置"><a href="#下面进行简单的配置" class="headerlink" title="下面进行简单的配置"></a>下面进行简单的配置</h3><p>按下图所示设置JDK、Maven：<code>[Manage Jenkins]-&gt;[Global Tool Configuration]</code>：<br><img src="/img/jenkins-6.png" alt="" title="设置"><br><img src="/img/jenkins-7.png" alt="" title="设置"></p>
<h3 id="下面安装插件"><a href="#下面安装插件" class="headerlink" title="下面安装插件"></a>下面安装插件</h3><p><code>[Manage Jenkins]-&gt;[Manage Plugins]</code><br>安装<code>Maven Integration</code>插件，如下图，直接点击<code>Install wthout restart</code>，该插件是用于建立maven job<br><img src="/img/jenkins-8.png" alt="" title="安装maven插件"></p>
<p>安装<code>Deploy to container</code>插件，用于将构建好的应用部署到容器中：<br><img src="/img/jenkins-9.png" alt="" title="安装Deploy to container插件"></p>
<h3 id="下面演示构建项目"><a href="#下面演示构建项目" class="headerlink" title="下面演示构建项目"></a>下面演示构建项目</h3><p>首先构建一个从gitHub中拉取原码的项目</p>
<p>未完待续……</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/10/05/jenkins-install/" data-id="cjmx9pod6000yvt2ievjlkkyz" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/jenkins/">jenkins</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ELK-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/02/ELK-install/" class="article-date">
  <time datetime="2018-10-02T03:09:56.000Z" itemprop="datePublished">2018-10-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/02/ELK-install/">ELK 日志系统的搭建</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本篇将介绍 ELK 日志系统的搭建，我们将在一台机器上面搭建，系统配置如下：<br><img src="/img/system-property.png" alt="" title="系统配置"></p>
<p><code>logstash</code>的整体结构图如下：<br><img src="/img/elk-structure.png" alt="" title="来源：https://www.elastic.co/guide/en/logstash/current/static/images/basic_logstash_pipeline.png"></p>
<p>我们将使用<code>redis</code>作为上图中的<code>INPUTS</code>，而<code>elasticsearch</code>作为上图中的<code>OUTPUTS</code>，这也是<code>logstash</code>官方的推荐。而它们的安装可以参考以下例子：<br><code>redis</code>的安装请参考：<a href="../../../../2018/08/07/redis-install/">redis 的安装使用</a><br><code>elasticsearch</code>的安装请参考：<a href="../../../../2018/09/16/elasticsearch-install/">elasticsearch 单节点安装</a></p>
<p><strong> 注意：elasticsearch、logstash、kibana它们的版本最好保持一致，这里都是使用6.4.0版本。 </strong></p>
<h3 id="kibana的安装将在本篇的稍后介绍，下面先介绍下logstash的安装"><a href="#kibana的安装将在本篇的稍后介绍，下面先介绍下logstash的安装" class="headerlink" title="kibana的安装将在本篇的稍后介绍，下面先介绍下logstash的安装"></a><code>kibana</code>的安装将在本篇的稍后介绍，下面先介绍下<code>logstash</code>的安装</h3><p>首先，我们要将<code>logstash</code>安装包下载回来，可以在它的<a href="https://artifacts.elastic.co/downloads/logstash/logstash-6.4.0.tar.gz" target="_blank" rel="noopener">官网</a>下载，当然，我们也可以从这里下载 <a href="https://pan.baidu.com/s/10p4YqzwSk1ixLqvSuv2sAA" title="百度网盘" target="_blank" rel="noopener">logstash-6.4.0.tar.gz</a>，推荐从<code>logstash</code>官网下载对应版本。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/logstash/logstash-6.4.0.tar.gz</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/logstash/logstash-6.4.0.tar.gz.sha512</span><br><span class="line"></span><br><span class="line">验证下载文件的完整性，在下载的时候要将 SHA512 文件也下载回来</span><br><span class="line">$ sha512sum -c logstash-6.4.0.tar.gz.sha512 </span><br><span class="line">logstash-6.4.0.tar.gz: OK</span><br><span class="line"></span><br><span class="line">$ tar xzf logstash-6.4.0.tar.gz</span><br></pre></td></tr></table></figure>
<p>解压后，得到目录<code>logstash-6.4.0</code>，可以查看下它包含有哪些文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/logstash-6.4.0</span><br><span class="line">$ ls</span><br><span class="line"></span><br><span class="line">bin           data          lib          logstash-core             NOTICE.TXT  x-pack</span><br><span class="line">config        Gemfile       LICENSE.txt  logstash-core-plugin-api  tools</span><br><span class="line">CONTRIBUTORS  Gemfile.lock  logs         modules                   vendor</span><br></pre></td></tr></table></figure></p>
<h4 id="测试安装是否成功：以标准输入、标准输出作为input-output"><a href="#测试安装是否成功：以标准输入、标准输出作为input-output" class="headerlink" title="测试安装是否成功：以标准输入、标准输出作为input, output"></a>测试安装是否成功：以标准输入、标准输出作为input, output</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/logstash-6.4.0/bin</span><br><span class="line">$ ./logstash -e <span class="string">'input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123; &#125; &#125;'</span></span><br><span class="line"></span><br><span class="line">Sending Logstash logs to /home/hewentian/ProjectD/logstash-6.4.0/logs <span class="built_in">which</span> is now configured via log4j2.properties</span><br><span class="line">[2018-10-02T14:25:37,017][WARN ][logstash.config.source.multilocal] Ignoring the <span class="string">'pipelines.yml'</span> file because modules or <span class="built_in">command</span> line options are specified</span><br><span class="line">[2018-10-02T14:25:38,201][INFO ][logstash.runner          ] Starting Logstash &#123;<span class="string">"logstash.version"</span>=&gt;<span class="string">"6.4.0"</span>&#125;</span><br><span class="line">[2018-10-02T14:25:41,748][INFO ][logstash.pipeline        ] Starting pipeline &#123;:pipeline_id=&gt;<span class="string">"main"</span>, <span class="string">"pipeline.workers"</span>=&gt;4, <span class="string">"pipeline.batch.size"</span>=&gt;125, <span class="string">"pipeline.batch.delay"</span>=&gt;50&#125;</span><br><span class="line">[2018-10-02T14:25:41,919][INFO ][logstash.pipeline        ] Pipeline started successfully &#123;:pipeline_id=&gt;<span class="string">"main"</span>, :thread=&gt;<span class="string">"#&lt;Thread:0x4c1685e4 run&gt;"</span>&#125;</span><br><span class="line">The stdin plugin is now waiting <span class="keyword">for</span> input:</span><br><span class="line">[2018-10-02T14:25:41,990][INFO ][logstash.agent           ] Pipelines running &#123;:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]&#125;</span><br><span class="line">[2018-10-02T14:25:42,396][INFO ][logstash.agent           ] Successfully started Logstash API endpoint &#123;:port=&gt;9600&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#此时窗口在等待输入</span></span><br><span class="line"></span><br><span class="line">hello world</span><br><span class="line"></span><br><span class="line"><span class="comment">#下面是logstash的输出结果</span></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">      <span class="string">"@version"</span> =&gt; <span class="string">"1"</span>,</span><br><span class="line">    <span class="string">"@timestamp"</span> =&gt; 2018-10-02T06:25:59.608Z,</span><br><span class="line">       <span class="string">"message"</span> =&gt; <span class="string">"hello world"</span>,</span><br><span class="line">          <span class="string">"host"</span> =&gt; <span class="string">"hewentian-Lenovo-IdeaPad-Y470"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从上面的测试结果可知，软件安装正确，下面开始我们的定制配置。</p>
<p>配置文件放在config目录下，此目录下已经有一个示例配置，因为我们要将redis作为我们的INPUTS，所以我们要建立它的配置文件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/logstash-6.4.0/config</span><br><span class="line">$ cp logstash-sample.conf logstash-redis.conf</span><br><span class="line">$ </span><br><span class="line">$ vi logstash-redis.conf</span><br></pre></td></tr></table></figure></p>
<p>在<code>logstash-redis.conf</code>中配置如下，这里暂未配置FILTERS（后面会讲到如何配置）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sample Logstash configuration for creating a simple</span></span><br><span class="line"><span class="comment"># Redis -&gt; Logstash -&gt; Elasticsearch pipeline.</span></span><br><span class="line"></span><br><span class="line">input &#123;</span><br><span class="line">  redis &#123;</span><br><span class="line">    <span class="built_in">type</span> =&gt; <span class="string">"systemlog"</span></span><br><span class="line">    host =&gt; <span class="string">"127.0.0.1"</span></span><br><span class="line">    port =&gt; 6379</span><br><span class="line">    password =&gt; <span class="string">"abc123"</span></span><br><span class="line">    db =&gt; 0</span><br><span class="line">    data_type =&gt; <span class="string">"list"</span></span><br><span class="line">    key =&gt; <span class="string">"systemlog"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  <span class="keyword">if</span> [<span class="built_in">type</span>] == <span class="string">"systemlog"</span> &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">      hosts =&gt; [<span class="string">"http://127.0.0.1:9200"</span>]</span><br><span class="line">      index =&gt; <span class="string">"redis-systemlog-%&#123;+YYYY.MM.dd&#125;"</span></span><br><span class="line">      <span class="comment">#user =&gt; "elastic"</span></span><br><span class="line">      <span class="comment">#password =&gt; "changeme"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>在启动<code>logstash</code>前，验证一下配置文件是否正确，这是一个好习惯：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/logstash-6.4.0/bin</span><br><span class="line">$ ./logstash -f ../config/logstash-redis.conf -t</span><br></pre></td></tr></table></figure></p>
<p>如果你见到如下输出，则配置正确：</p>
<pre><code>Sending Logstash logs to /home/hewentian/ProjectD/logstash-6.4.0/logs which is now configured via log4j2.properties
[2018-09-30T16:32:45,043][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=&gt;&quot;path.queue&quot;, :path=&gt;&quot;/home/hewentian/ProjectD/logstash-6.4.0/data/queue&quot;}
[2018-09-30T16:32:45,064][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=&gt;&quot;path.dead_letter_queue&quot;, :path=&gt;&quot;/home/hewentian/ProjectD/logstash-6.4.0/data/dead_letter_queue&quot;}
[2018-09-30T16:32:46,030][WARN ][logstash.config.source.multilocal] Ignoring the &apos;pipelines.yml&apos; file because modules or command line options are specified
Configuration OK
[2018-09-30T16:32:50,630][INFO ][logstash.runner          ] Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash
</code></pre><p>接下来，就可以启动logstash了：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/logstash-6.4.0/bin</span><br><span class="line">$ ./logstash -f ../config/logstash-redis.conf</span><br></pre></td></tr></table></figure></p>
<p>如果见到如下输出，则启动成功：</p>
<pre><code>[2018-09-30T16:34:44,175][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=&gt;9600}
</code></pre><h4 id="下面进行简单的测试"><a href="#下面进行简单的测试" class="headerlink" title="下面进行简单的测试"></a>下面进行简单的测试</h4><p>我们首先，往redis中推入3条记录：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/redis-4.0.11_master/src</span><br><span class="line">$ ./redis-cli -h 127.0.0.1</span><br><span class="line">127.0.0.1:6379&gt; AUTH abc123</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; lpush systemlog hello world</span><br><span class="line">(<span class="built_in">integer</span>) 2</span><br><span class="line">127.0.0.1:6379&gt; lpush systemlog <span class="string">'&#123;"name":"Tim Ho","age":23,"student":true&#125;'</span></span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br></pre></td></tr></table></figure></p>
<p>启动elastchsearch-head可以看到数据已经进入到es中了：<br><img src="/img/elk-head-1.png" alt="" title="elk-head-1"></p>
<p>你会发现上面推到<code>systemlog</code>中的信息如果是JSON格式，则在elasticsearch中会自动解析到相应的field中，否则会放到默认的field：<code>message</code>中。</p>
<h3 id="kibana的安装"><a href="#kibana的安装" class="headerlink" title="kibana的安装"></a>kibana的安装</h3><p><code>kibana</code>的安装很简单，将<code>kibana</code>安装包下载回来，可以在它的<a href="https://artifacts.elastic.co/downloads/kibana/kibana-6.4.0-linux-x86_64.tar.gz" target="_blank" rel="noopener">官网</a>下载，当然，我们也可以从这里下载 <a href="https://pan.baidu.com/s/1-h0z7DR2uhuwhCn0_vNc4w" title="百度网盘" target="_blank" rel="noopener">kibana-6.4.0-linux-x86_64.tar.gz</a>，推荐从<code>kibana</code>官网下载对应版本。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/kibana/kibana-6.4.0-linux-x86_64.tar.gz</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/kibana/kibana-6.4.0-linux-x86_64.tar.gz.sha512</span><br><span class="line"></span><br><span class="line">验证下载文件的完整性，在下载的时候要将 SHA512 文件也下载回来</span><br><span class="line">$ sha512sum -c kibana-6.4.0-linux-x86_64.tar.gz.sha512 </span><br><span class="line">kibana-6.4.0-linux-x86_64.tar.gz: OK</span><br><span class="line"></span><br><span class="line">$ tar xzf kibana-6.4.0-linux-x86_64.tar.gz</span><br></pre></td></tr></table></figure>
<p>对<code>kibana</code>配置要查看的<code>elasticsearch</code>，只需修改如下配置项即可，如果是在本机安装<code>elasticsearch</code>，并且使用默认的9200端口，则无需配置。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kibana-6.4.0-linux-x86_64/config</span><br><span class="line">$ vi kibana.yml</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改如下配置项，如果使用默认的，则无需修改</span></span><br><span class="line"><span class="comment">#server.port: 5601</span></span><br><span class="line"><span class="comment">#elasticsearch.url: "http://localhost:9200"</span></span><br><span class="line"><span class="comment">#elasticsearch.username: "user"</span></span><br><span class="line"><span class="comment">#elasticsearch.password: "pass"</span></span><br></pre></td></tr></table></figure></p>
<p>接着启动<code>kibana</code>：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kibana-6.4.0-linux-x86_64/bin</span><br><span class="line">$ ./kibana <span class="comment"># 或者以后台方式运行 nohup ./kibana &amp;</span></span><br></pre></td></tr></table></figure></p>
<p>打开浏览器，并输入下面的地址：<br><a href="http://localhost:5601" target="_blank" rel="noopener">http://localhost:5601</a></p>
<p>你将看到如下界面：<br><img src="/img/elk-kibana-1.png" alt="" title="kibana初始界面"></p>
<p>点击上图中的<code>[Management]-&gt;[Index Patterns]-&gt;[Create index pattern]</code>，输入<code>index name：redis-systemlog-*</code>，如下图<br><img src="/img/elk-kibana-2.png" alt="" title="kibana配置index name界面"></p>
<p>点击<code>[Next step]</code>按钮，并在接下来的界面中的<code>Time Filter field name</code>中选择<code>I don&#39;t want to user the Time Filter</code>，最后点击<code>Create index pattern</code>完成创建。接着点击左则的<code>[Discover]</code>并在左则的界面中选择中<code>redis-systemlog-*</code>，你将看到如下结果：<br><img src="/img/elk-kibana-3.png" alt="" title="kibana查询界面"></p>
<p>至此，简单的 ELK 基本搭建完毕。下面展示一个简单的配置示例：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sample Logstash configuration for creating a simple</span></span><br><span class="line"><span class="comment"># Redis -&gt; Logstash -&gt; Elasticsearch pipeline.</span></span><br><span class="line"></span><br><span class="line">input &#123;</span><br><span class="line">  <span class="comment"># system log</span></span><br><span class="line">  redis &#123;</span><br><span class="line">    <span class="built_in">type</span> =&gt; <span class="string">"systemlog"</span></span><br><span class="line">    host =&gt; <span class="string">"127.0.0.1"</span></span><br><span class="line">    port =&gt; 6379</span><br><span class="line">    password =&gt; <span class="string">"abc123"</span></span><br><span class="line">    db =&gt; 0</span><br><span class="line">    data_type =&gt; <span class="string">"list"</span></span><br><span class="line">    key =&gt; <span class="string">"systemlog"</span></span><br><span class="line">    codec  =&gt; <span class="string">"json"</span></span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># user log</span></span><br><span class="line">  redis &#123;</span><br><span class="line">    <span class="built_in">type</span> =&gt; <span class="string">"userlog"</span></span><br><span class="line">    host =&gt; <span class="string">"127.0.0.1"</span></span><br><span class="line">    port =&gt; 6379</span><br><span class="line">    password =&gt; <span class="string">"abc123"</span></span><br><span class="line">    db =&gt; 0</span><br><span class="line">    data_type =&gt; <span class="string">"list"</span></span><br><span class="line">    key =&gt; <span class="string">"userlog"</span></span><br><span class="line">    codec  =&gt; <span class="string">"json"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; [<span class="string">"http://127.0.0.1:9200"</span>]</span><br><span class="line">    index =&gt; <span class="string">"%&#123;type&#125;-%&#123;+YYYY.MM&#125;"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="下面我们将继续探索它的高级功能。"><a href="#下面我们将继续探索它的高级功能。" class="headerlink" title="下面我们将继续探索它的高级功能。"></a>下面我们将继续探索它的高级功能。</h3><p>很多时候，对于<code>systemlog</code>中的某条信息（不一定是JSON格式），如果我们只需要某些信息，那我们又怎样做呢？这里就需要使用FILTERS了。</p>
<p>在FILTERS中使用grok正则表达式，关于grok，可以参见这里的说明：<br><a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html</a></p>
<p>未完，待续……</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/10/02/ELK-install/" data-id="cjmx9poau0000vt2i05fxof4o" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-elasticsearch-note" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/18/elasticsearch-note/" class="article-date">
  <time datetime="2018-09-18T02:21:01.000Z" itemprop="datePublished">2018-09-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/18/elasticsearch-note/">elasticsearch 学习笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>参考资料：<br><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/index.html" title="Elasticsearch 权威指南" target="_blank" rel="noopener">Elasticsearch 权威指南</a><br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html" title="Elasticsearch Reference" target="_blank" rel="noopener">Elasticsearch Reference</a><br><a href="http://es.xiaoleilu.com/080_Structured_Search/20_contains.html" target="_blank" rel="noopener">http://es.xiaoleilu.com/080_Structured_Search/20_contains.html</a><br><a href="https://github.com/searchbox-io/Jest/tree/master/jest/src/test/java/io/searchbox/core">https://github.com/searchbox-io/Jest/tree/master/jest/src/test/java/io/searchbox/core</a></p>
<p>首先，你必须至少有一台<code>elasticsearch</code>服务器可以使用，如果还没安装，可以参考我的上两篇 <a href="../../../../2018/09/16/elasticsearch-install" title="elasticsearch 单节点安装">elasticsearch 单节点安装</a>、<a href="../../../../2018/09/17/elasticsearch-cluster" title="elasticsearch 集群的搭建">elasticsearch 集群的搭建</a></p>
<p>使用JAVA API来操作<code>elasticsearch</code>的例子可以在这里找到：<a href="https://github.com/hewentian/studyResource/blob/master/src/main/java/com/hewentian/util/EsJestUtil.java">EsJestUtil.java</a>、<a href="https://github.com/hewentian/studyResource/blob/master/src/main/java/com/hewentian/es/EsJestDemo.java">EsJestDemo.java</a></p>
<h4 id="要单独创建一个索引"><a href="#要单独创建一个索引" class="headerlink" title="要单独创建一个索引"></a>要单独创建一个索引</h4><pre>
curl -XPUT 'http://localhost:9200/user_index' -H 'Content-Type: application/json' -d '{
    "settings" : {
        "index" : {
            "number_of_shards" : 4,
            "number_of_replicas" : 1
        }
    }
}'

{"acknowledged":true,"shards_acknowledged":true,"index":"user_index"}
</pre>


<h4 id="删除索引的命令"><a href="#删除索引的命令" class="headerlink" title="删除索引的命令"></a>删除索引的命令</h4><pre>
curl -XDELETE 'http://localhost:9200/user_index/'

{"acknowledged":true}
</pre>


<h4 id="为user-index中的user创建mapping"><a href="#为user-index中的user创建mapping" class="headerlink" title="为user_index中的user创建mapping"></a>为user_index中的user创建mapping</h4><pre>
curl -XPUT 'http://localhost:9200/user_index/_mapping/user' -H 'Content-Type: application/json' -d '{
    "properties": {
        "id": {
            "type": "long",
            "index": "false"
        },
        "name": {
            "type": "keyword"
        },
        "age": {
            "type": "integer"
        },
        "tags": {
            "type": "keyword",
            "boost": 3.0
       },
       "birthday": {
            "type": "date",
            "format": "strict_date_optional_time || epoch_millis || yyyy-MM-dd HH:mm:ss"
       }
   }
}'
</pre>


<h4 id="ES中的一些概念"><a href="#ES中的一些概念" class="headerlink" title="ES中的一些概念"></a>ES中的一些概念</h4><p><strong>cluster</strong><br>代表一个集群，集群中有多个节点，其中有一个为主节点，这个主节点是可以通过选举产生的，主从节点是对于集群内部来说的。es的一个概念就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部来看es集群，在逻辑上是个整体，你与任何一个节点的通信和与整个es集群通信是等价的。</p>
<p><strong>shards</strong><br>代表索引分片，es可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。</p>
<p><strong>replicas</strong><br>代表索引副本，es可以设置多个索引的副本，副本的作用一是提高系统的容错性，当某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡。</p>
<p><strong>recovery</strong><br>代表数据恢复或叫数据重新分布，es在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，挂掉的节点重新启动时也会进行数据恢复。</p>
<p><strong>river</strong><br>代表es的一个数据源，也是其它存储方式（如：数据库）同步数据到es的一个方法。它是以插件方式存在的一个es服务，通过读取river中的数据并把它索引到es中，官方的river有couchDB的，RabbitMQ的，Twitter的，Wikipedia的。</p>
<p><strong>gateway</strong><br>代表es索引快照的存储方式，es默认是先把索引存放到内存中，当内存满了时再持久化到本地硬盘。gateway对索引快照进行存储，当这个es集群关闭再重新启动时就会从gateway中读取索引备份数据。es支持多种类型的gateway，有本地文件系统（默认），分布式文件系统，Hadoop的HDFS和amazon的s3云存储服务。</p>
<p><strong>discovery.zen</strong><br>代表es的自动发现节点机制，es是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过多播协议来进行节点之间的通信，同时也支持点对点的交互。</p>
<p><strong>Transport</strong><br>代表es内部节点或集群与客户端的交互方式，默认内部是使用tcp协议进行交互，同时它支持http协议（json格式）、thrift、servlet、memcached、zeroMQ等的传输协议（通过插件方式集成）。</p>
<p>Date formats can be customised, but if no format is specified then it uses the default:</p>
<pre><code>&quot;strict_date_optional_time||epoch_millis&quot;
</code></pre><p>if you set it like this:</p>
<pre><code>PUT my_index
{
  &quot;mappings&quot;: {
    &quot;_doc&quot;: {
      &quot;properties&quot;: {
        &quot;date&quot;: {
          &quot;type&quot;:   &quot;date&quot;,
          &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;
        }
      }
    }
  }
}
</code></pre><p>you can use the below method to set date:</p>
<pre>
PUT my_index/_doc/1
{ "date": "2015-01-01 12:10:30" } 

PUT my_index/_doc/2
{ "date": "2015-01-01T12:10:30Z" } 

PUT my_index/_doc/3
{ "date": 1420070400001 }
</pre>

<h4 id="文件的部分更新"><a href="#文件的部分更新" class="headerlink" title="文件的部分更新"></a>文件的部分更新</h4><p>文档是不可变的：他们不能被修改，只能被替换。 update API 必须遵循同样的规则。 从外部来看，我们在一个文档的某个位置进行部分更新。然而在内部， update API 简单使用与之前描述相同的 检索-修改-重建索引 的处理过程。 区别在于这个过程发生在分片内部，这样就避免了多次请求的网络开销。通过减少检索和重建索引步骤之间的时间，我们也减少了其他进程的变更带来冲突的可能性。</p>
<p>方法一：update 请求最简单的一种形式是接收文档的一部分作为 doc 的参数， 它只是与现有的文档进行合并。对象被合并到一起，覆盖现有的字段，增加新的字段。 例如，我们增加字段 tags 和 views 到我们的博客文章，如下所示：</p>
<pre><code>POST /website/blog/1/_update
{
       &quot;doc&quot; : {
          &quot;tags&quot; : [ &quot;testing&quot; ],
          &quot;views&quot;: 0
       }
}
</code></pre><p>测试示例：</p>
<pre>
先插件一条数据：
curl -XPUT 'http://localhost:9200/facebook/tuser/1?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "tim",
    "post_date": "2009-11-15T13:12:00",
    "message": "Elasticsearch, so far so good?"
}'

再将这条数所的 message 字段修改一下
curl -XPOST 'http://localhost:9200/facebook/tuser/1/_update' -H 'Content-Type: application/json' -d '
{
    "doc":{
        "message": "Elasticsearch, so far so good? yes"
    }
}'
</pre>


<p>方法二：使用脚本部分更新文档编辑<br>脚本可以在 update API中用来改变 _source 的字段内容， 它在更新脚本中称为 ctx._source 。 例如，我们可以使用脚本来增加博客文章中 views 的数量：</p>
<pre><code>POST /website/blog/1/_update
{
       &quot;script&quot; : &quot;ctx._source.views+=1&quot;
}
</code></pre><pre>
curl -XPOST 'http://127.0.0.1:9200/facebook/tuser/1/_update' -H 'Content-Type: application/json' -d '
{
    "script" : "ctx._source.message=\"yes, you are right.\""
}'
</pre>

<p>下面的命令可以列出每个 Index 所包含的 Type<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl -XGET <span class="string">'http://127.0.0.1:9200/user_index/_mapping?pretty=true'</span></span><br></pre></td></tr></table></figure></p>
<ol>
<li>cluster.name<br>配置es的集群名称，默认是elasticsearch，不同的集群用名字来区分，es会自动发现在同一网段下的es，配置成相同集群名字的各个节点形成一个集群。如果在同一网段下有多个集群，就可以用这个属性来区分不同的集群。</li>
<li>http.port<br>设置对外服务的http端口，默认为9200。不能相同，否则会冲突。</li>
</ol>
<p>ES有很多插件，我们可以选择安装一些，例如，以安装head插件为例。有两种方式安装，一种为在线安装，另一种为本地安装，本地安装要下载插件(git clone)。<br>插件下载地址为：<br><a href="https://github.com/mobz/elasticsearch-head">https://github.com/mobz/elasticsearch-head</a></p>
<p>这里以在线安装为例，我之前在介绍<a href="../../../../2018/09/16/elasticsearch-install" title="elasticsearch 单节点安装">elasticsearch 单节点安装</a>中使用的是本地安装，推荐使用本地安装。旧版本安装过程如下：<br>进入ES的HOME目录，执行plugin命令，如下，</p>
<pre><code>cd ${ES_HOME}/bin
./elasticsearch-plugin install mobz/elasticsearch-head
</code></pre><p>安装完毕后，要重启ES。在浏览器中输入：<a href="http://localhost:9200/_plugin/head/，如果看到了页面，则表明安装成功。" target="_blank" rel="noopener">http://localhost:9200/_plugin/head/，如果看到了页面，则表明安装成功。</a></p>
<p>ES一次查询，最多返回10条，但hits会显示total一共有多少条，要使用from, size指定。<br>在ES里面删除数据的时候要非常小心，如果全部都清空了，可能整个库的MAPPING都会有问题。这时，一些原先可以执行的语句可能会无法执行</p>
<h4 id="以下是一些常查询："><a href="#以下是一些常查询：" class="headerlink" title="以下是一些常查询："></a>以下是一些常查询：</h4><pre>
{
  "query": {
    "bool": {
      "should": [
        {
          "match": {
            "_id": "http://www.abc.com"
          }
        },
        {
          "match": {
            "_id": "http://www.csdn.net/tag/scala"
          }
        }
      ]
    }
  }
}


{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "address": "*canton*"
          }
        },
        {
          "match": {
            "name": "Tim"
          }
        }
      ]
    }
  }
}


{
  "query": {
    "bool": {
      "must": [
        {
          "bool": {
            "should": [
              {
                "match": {
                  "title": {
                    "minimum_should_match": "100%",
                    "query": "Air Quality"
                  }
                }
              },
              {
                "match": {
                  "body_text": {
                    "minimum_should_match": "100%",
                    "query": "Air Quality"
                  }
                }
              }
            ]
          }
        },
        {
          "wildcard": {
            "user_ids": "*760aa069-2ed2-40d6-89da-f62e83f82887*"
          }
        }
      ]
    }
  },
  "from": 0,
  "size": 20
}


{
  "sort": [
    {
      "updatetime_6h": {
        "order": "desc"
      }
    },
    {
      "_score": {
        "order": "desc"
      }
    }
  ],
  "query": {
    "filtered": {
      "query": {
        "bool": {
          "must_not": [],
          "should": [
            {
              "bool": {
                "should": [
                  {
                    "match_phrase": {
                      "app_type.title": {
                        "query": "china"
                      }
                    }
                  },
                  {
                    "match_phrase": {
                      "app_type.title": {
                        "query": "中国"
                      }
                    }
                  }
                ]
              }
            },
            {
              "bool": {
                "should": [
                  {
                    "match_phrase": {
                      "app_type.body_text": {
                        "query": "china"
                      }
                    }
                  },
                  {
                    "match_phrase": {
                      "app_type.body_text": {
                        "query": "中国"
                      }
                    }
                  }
                ]
              }
            }
          ],
          "must": []
        }
      },
      "filter": {
        "bool": {
          "should": [],
          "must": [
            {
              "range": {
                "updatetime": {
                  "lte": 1474617163524
                }
              }
            },
            {
              "query": {
                "wildcard": {
                  "user_ids": "*760aa069-2ed2-40d6-89da-f62e83f82887*"
                }
              }
            }
          ]
        }
      }
    }
  },
  "from": 0,
  "size": 20
}
</pre>

<p>未完待续……</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/09/18/elasticsearch-note/" data-id="cjmx9poc20009vt2imwalnepl" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-elasticsearch-cluster" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/17/elasticsearch-cluster/" class="article-date">
  <time datetime="2018-09-17T02:36:12.000Z" itemprop="datePublished">2018-09-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/17/elasticsearch-cluster/">elasticsearch 集群的搭建</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>下面说说elasticsearch集群的搭建，同样是使用前面例子<a href="../../../../2018/09/16/elasticsearch-install" title="elasticsearch 安装">elasticsearch 单节点安装</a>使用的<code>elasticsearch-6.4.0.tar.gz</code>版本，我在一台机器上安装，所以这是伪集群，当修改为真集群的时候，只要将IP地址修改下即可，下面会说明。</p>
<h3 id="下面开始搭建elasticsearch集群"><a href="#下面开始搭建elasticsearch集群" class="headerlink" title="下面开始搭建elasticsearch集群"></a>下面开始搭建elasticsearch集群</h3><p>创建一个目录用于存放集群使用到的所有实例信息<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD</span><br><span class="line">$ mkdir elasticsearchCluster	<span class="comment"># 集群的文件都放在这里</span></span><br></pre></td></tr></table></figure></p>
<p>将一个elasticsearch压缩包放到这个目录，我之前已在ProjectD目录下载好了<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster</span><br><span class="line">$ cp /home/hewentian/ProjectD/elasticsearch-6.4.0.tar.gz ./</span><br><span class="line">$ tar xzvf elasticsearch-6.4.0.tar.gz</span><br><span class="line"></span><br><span class="line">为方便起见，这里将其重命名为elasticsearch-node1，先将elasticsearch-node1配置好，</span><br><span class="line">后面会将其复制为elasticsearch-node2, elasticsearch-node3</span><br><span class="line">$ mv elasticsearch-6.4.0 elasticsearch-node1</span><br></pre></td></tr></table></figure></p>
<p>对<code>elasticsearch-node1</code>进行设置：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node1/config</span><br><span class="line">$ vi elasticsearch.yml 		<span class="comment"># 增加下面的配置</span></span><br><span class="line"></span><br><span class="line">cluster.name: hewentian-cluster	<span class="comment"># 配置集群的名字</span></span><br><span class="line">node.name: node-1		<span class="comment"># 配置集群下的节点的名字</span></span><br><span class="line"></span><br><span class="line">node.master: <span class="literal">true</span>		<span class="comment"># 是否有资格被选举为master节点， 默认为 true</span></span><br><span class="line">node.data: <span class="literal">true</span>			<span class="comment"># 设置该节点是否存储数据， 默认为 true</span></span><br><span class="line"></span><br><span class="line">network.host: 127.0.0.1		<span class="comment"># 设置本机IP地址</span></span><br><span class="line">http.port: 9201			<span class="comment"># 将端口设置成9201</span></span><br><span class="line">transport.tcp.port: 9301	<span class="comment"># 内部节点之间沟通的端口</span></span><br><span class="line"></span><br><span class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"127.0.0.1:9301"</span>, <span class="string">"127.0.0.1:9302"</span>, <span class="string">"127.0.0.1:9303"</span>]</span><br><span class="line"></span><br><span class="line">discovery.zen.minimum_master_nodes: 2	<span class="comment"># total number of master-eligible nodes / 2 + 1</span></span><br><span class="line"></span><br><span class="line">action.destructive_requires_name: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">允许跨域，否则 elasticsearch head 不能访问 elasticsearch</span><br><span class="line">http.cors.enabled: <span class="literal">true</span></span><br><span class="line">http.cors.allow-origin: <span class="string">"*"</span></span><br></pre></td></tr></table></figure></p>
<p>这样一个节点就配置好了，我们只要以这个为蓝本，复制出两份，并修改其中的三点：node.name、http.port、transport.tcp.port即可。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster</span><br><span class="line">$ cp -r elasticsearch-node1 elasticsearch-node2</span><br><span class="line">$ cp -r elasticsearch-node1 elasticsearch-node3</span><br><span class="line"></span><br><span class="line">$ ls </span><br><span class="line">elasticsearch-6.4.0.tar.gz  elasticsearch-node1  elasticsearch-node2  elasticsearch-node3</span><br><span class="line"></span><br><span class="line">对 elasticsearch-node2 进行设置，只修改如下三项</span><br><span class="line">$ vi /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node2/config/elasticsearch.yml</span><br><span class="line"></span><br><span class="line">node.name: node-2</span><br><span class="line">http.port: 9202</span><br><span class="line">transport.tcp.port: 9302</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">对 elasticsearch-node3 进行设置，只修改如下三项</span><br><span class="line">$ vi /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node3/config/elasticsearch.yml</span><br><span class="line"></span><br><span class="line">node.name: node-3</span><br><span class="line">http.port: 9203</span><br><span class="line">transport.tcp.port: 9303</span><br></pre></td></tr></table></figure></p>
<p>内存大小的设置，根据机器内存大小而设置，一般不超过系统总内存的一半，分别对三个节点进行：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node1/config/</span><br><span class="line">$ vi jvm.options</span><br><span class="line"></span><br><span class="line">-Xms1g</span><br><span class="line">-Xmx1g</span><br></pre></td></tr></table></figure></p>
<p>在每个节点所在的机器上都作下面的配置（下面是根据我机器的情况作的配置，我的是伪集群，所以只配置一次）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ su root			<span class="comment"># 必须在 root 下才有权限修改系统配置文件</span></span><br><span class="line">Password: </span><br><span class="line">$ vi /etc/security/limits.conf	<span class="comment"># 添加如下配置</span></span><br><span class="line">* soft nofile 65536		<span class="comment"># 上面第一个错误有提示</span></span><br><span class="line">* hard nofile 131072		<span class="comment"># 一般为 soft nofile 的2倍</span></span><br><span class="line">* soft nproc 4096		<span class="comment"># 这个设置线程数</span></span><br><span class="line">* hard nproc 8192</span><br><span class="line"></span><br><span class="line">$ vi /etc/sysctl.conf		<span class="comment"># 添加如下配置</span></span><br><span class="line">vm.max_map_count=262144</span><br><span class="line"></span><br><span class="line">$ sysctl -p			<span class="comment"># 最后执行这个命令，你会见到如下输出</span></span><br><span class="line">vm.max_map_count=262144</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">exit</span>				<span class="comment"># 退出 root</span></span><br></pre></td></tr></table></figure></p>
<p>分别启动三个节点：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node1/bin</span><br><span class="line">$ ./elasticsearch</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node2/bin</span><br><span class="line">$ ./elasticsearch</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node3/bin</span><br><span class="line">$ ./elasticsearch</span><br></pre></td></tr></table></figure></p>
<p>部分输出如下：</p>
<pre><code>[2018-09-17T17:27:08,325][INFO ][o.e.n.Node               ] [node-1] initializing ...
[2018-09-17T17:27:08,430][INFO ][o.e.e.NodeEnvironment    ] [node-1] using [1] data paths, mounts [[/ (/dev/sda2)]], net usable_space [59.7gb], net total_space [101.7gb], types [ext4]

[2018-09-17T17:27:19,552][DEBUG][o.e.a.ActionModule       ] Using REST wrapper from plugin org.elasticsearch.xpack.security.Security
[2018-09-17T17:27:19,878][INFO ][o.e.d.DiscoveryModule    ] [node-1] using discovery type [zen]
[2018-09-17T17:27:21,289][INFO ][o.e.n.Node               ] [node-1] initialized
[2018-09-17T17:27:21,289][INFO ][o.e.n.Node               ] [node-1] starting ...
[2018-09-17T17:27:21,496][INFO ][o.e.t.TransportService   ] [node-1] publish_address {127.0.0.1:9301}, bound_addresses {127.0.0.1:9301}
[2018-09-17T17:27:24,571][WARN ][o.e.d.z.ZenDiscovery     ] [node-1] not enough master nodes discovered during pinging (found [[Candidate{node={node-1}{D7fISYxgQFahYdTEbqMO4g}{7x0Hu4tQTP-N73j_A073DA}{127.0.0.1}{127.0.0.1:9301}{ml.machine_memory=8305086464, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true}, clusterStateVersion=-1}]], but needed [2]), pinging again

发现节点 node-2
[2018-09-17T17:28:37,362][INFO ][o.e.c.s.MasterService    ] [node-1] zen-disco-elected-as-master ([1] nodes joined)[, ], reason: new_master {node-1}{D7fISYxgQFahYdTEbqMO4g}{7x0Hu4tQTP-N73j_A073DA}{127.0.0.1}{127.0.0.1:9301}{ml.machine_memory=8305086464, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true}, added {{node-2}{LNHhP-WPSDaGZJeRHYwBQQ}{zRaTzS0OQkyfCdaRhczR9A}{127.0.0.1}{127.0.0.1:9302}{ml.machine_memory=8305086464, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true},}

发现节点 node-3
[node-1] zen-disco-node-join, reason: added {{node-3}{4rqo1NL0R8KVCAkzI0w4UQ}{s599uwThRGi74YE4WFULIg}{127.0.0.1}{127.0.0.1:9303}{ml.machine_memory=8305086464, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true},}
[2018-09-17T17:29:27,022][INFO ][o.e.c.s.ClusterApplierService] [node-1] added {{node-3}{4rqo1NL0R8KVCAkzI0w4UQ}{s599uwThRGi74YE4WFULIg}{127.0.0.1}{127.0.0.1:9303}{ml.machine_memory=8305086464, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true},}, reason: apply cluster state (from master [master {node-1}{D7fISYxgQFahYdTEbqMO4g}{7x0Hu4tQTP-N73j_A073DA}{127.0.0.1}{127.0.0.1:9301}{ml.machine_memory=8305086464, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true} committed version [15] source [zen-disco-node-join]])
</code></pre><p>在浏览器中输入如下地址：<br><a href="http://localhost:9201/" target="_blank" rel="noopener">http://localhost:9201/</a><br><a href="http://localhost:9202/" target="_blank" rel="noopener">http://localhost:9202/</a><br><a href="http://localhost:9203/" target="_blank" rel="noopener">http://localhost:9203/</a></p>
<pre><code>{
  &quot;name&quot; : &quot;node-1&quot;,
  &quot;cluster_name&quot; : &quot;hewentian-cluster&quot;,
  &quot;cluster_uuid&quot; : &quot;odUSNw8jS4q-w_Vl66q1qg&quot;,
  &quot;version&quot; : {
    &quot;number&quot; : &quot;6.4.0&quot;,
    &quot;build_flavor&quot; : &quot;default&quot;,
    &quot;build_type&quot; : &quot;tar&quot;,
    &quot;build_hash&quot; : &quot;595516e&quot;,
    &quot;build_date&quot; : &quot;2018-08-17T23:18:47.308994Z&quot;,
    &quot;build_snapshot&quot; : false,
    &quot;lucene_version&quot; : &quot;7.4.0&quot;,
    &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,
    &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;
  },
  &quot;tagline&quot; : &quot;You Know, for Search&quot;
}

{
  &quot;name&quot; : &quot;node-2&quot;,
  &quot;cluster_name&quot; : &quot;hewentian-cluster&quot;,
  &quot;cluster_uuid&quot; : &quot;odUSNw8jS4q-w_Vl66q1qg&quot;,
  &quot;version&quot; : {
    &quot;number&quot; : &quot;6.4.0&quot;,
    &quot;build_flavor&quot; : &quot;default&quot;,
    &quot;build_type&quot; : &quot;tar&quot;,
    &quot;build_hash&quot; : &quot;595516e&quot;,
    &quot;build_date&quot; : &quot;2018-08-17T23:18:47.308994Z&quot;,
    &quot;build_snapshot&quot; : false,
    &quot;lucene_version&quot; : &quot;7.4.0&quot;,
    &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,
    &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;
  },
  &quot;tagline&quot; : &quot;You Know, for Search&quot;
}

{
  &quot;name&quot; : &quot;node-3&quot;,
  &quot;cluster_name&quot; : &quot;hewentian-cluster&quot;,
  &quot;cluster_uuid&quot; : &quot;odUSNw8jS4q-w_Vl66q1qg&quot;,
  &quot;version&quot; : {
    &quot;number&quot; : &quot;6.4.0&quot;,
    &quot;build_flavor&quot; : &quot;default&quot;,
    &quot;build_type&quot; : &quot;tar&quot;,
    &quot;build_hash&quot; : &quot;595516e&quot;,
    &quot;build_date&quot; : &quot;2018-08-17T23:18:47.308994Z&quot;,
    &quot;build_snapshot&quot; : false,
    &quot;lucene_version&quot; : &quot;7.4.0&quot;,
    &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,
    &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;
  },
  &quot;tagline&quot; : &quot;You Know, for Search&quot;
}
</code></pre><p>启动elasticsearch-head，我们就可以看到集群如下图所示：<br><img src="/img/elasticsearch-cluster-1.png" alt="" title="elasticsearch-集群"><br>从图中可以看到<code>node-1</code>已经成为master节点。我们尝试往集群中PUT一些数据，分别往3个不同的端口中PUT数据：</p>
<pre>
curl -XPUT 'http://localhost:9201/twitter/doc/1?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T13:12:00",
    "message": "Trying out Elasticsearch, so far so good?"
}'

curl -XPUT 'http://localhost:9202/twitter/doc/2?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T14:12:12",
    "message": "Another tweet, will it be indexed?"
}'

curl -XPUT 'http://localhost:9203/twitter/doc/3?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "elastic",
    "post_date": "2010-01-15T01:46:38",
    "message": "Building the site, should be kewl"
}'
</pre>

<p>输出结果如下：</p>
<pre>
{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "1",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "failed" : 0
  },
  "_seq_no" : 0,
  "_primary_term" : 1
}

{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "2",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "failed" : 0
  },
  "_seq_no" : 0,
  "_primary_term" : 1
}

{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "3",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "failed" : 0
  },
  "_seq_no" : 0,
  "_primary_term" : 1
}
</pre>

<h4 id="我们在elasticsearch-head中查看数据"><a href="#我们在elasticsearch-head中查看数据" class="headerlink" title="我们在elasticsearch-head中查看数据"></a>我们在elasticsearch-head中查看数据</h4><p>elasticsearch-集群状态：<br><img src="/img/elasticsearch-cluster-2.png" alt="" title="elasticsearch-集群状态"></p>
<p>elasticsearch-集群数据<br><img src="/img/elasticsearch-cluster-3.png" alt="" title="elasticsearch-集群数据"></p>
<p>至此，集群搭建结束。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/09/17/elasticsearch-cluster/" data-id="cjmx9pobv0006vt2iwr5ek7f5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-elasticsearch-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/16/elasticsearch-install/" class="article-date">
  <time datetime="2018-09-16T03:18:34.000Z" itemprop="datePublished">2018-09-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/16/elasticsearch-install/">elasticsearch 单节点安装</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文将说下<code>elasticsearch</code>的单节点安装，我的机器为<code>Ubuntu 16.04 LTS</code>，当前用户为<code>hewentian</code></p>
<p>首先，我们要将<code>elasticsearch</code>安装包下载回来，截止本文写时，它的最新版本为<code>6.4.0</code>，可以在它的<a href="https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.4.0.tar.gz" target="_blank" rel="noopener">官网</a>下载，当然，我们也可以从这里下载 <a href="https://pan.baidu.com/s/1Rns322X-h0D5pRaqaGPaZQ" title="百度网盘" target="_blank" rel="noopener">elasticsearch-6.4.0.tar.gz</a>，推荐从<code>elasticsearch</code>官网下载最新版本。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.4.0.tar.gz</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.4.0.tar.gz.sha512</span><br><span class="line"></span><br><span class="line">验证下载文件的完整性，在下载的时候要将 SHA512 文件也下载回来</span><br><span class="line">$ sha512sum -c elasticsearch-6.4.0.tar.gz.sha512 </span><br><span class="line">elasticsearch-6.4.0.tar.gz: OK</span><br><span class="line"></span><br><span class="line">$ tar xzf elasticsearch-6.4.0.tar.gz</span><br></pre></td></tr></table></figure>
<p>对<code>elasticsearch</code>进行设置（目前是单节点，所以也可以不对<code>elasticsearch.yml</code>进行设置，可直接跳过）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearch-6.4.0/config</span><br><span class="line">$ vi elasticsearch.yml 		<span class="comment"># 增加下面的配置</span></span><br><span class="line"></span><br><span class="line">cluster.name: hewentian-cluster	<span class="comment"># 配置集群的名字</span></span><br><span class="line">node.name: node-1		<span class="comment"># 配置集群下的节点的名字</span></span><br><span class="line"></span><br><span class="line">network.host: 127.0.0.1		<span class="comment"># 设置本机IP地址，这里可不设置，但是在集群环境中必须设置。如果在这里指定了IP，则localhost可能无法使用，这个要注意</span></span><br><span class="line"></span><br><span class="line">http.port: 9200			<span class="comment"># 默认也是这个端口</span></span><br><span class="line"></span><br><span class="line">下面的配置保持默认即可，它会将数据和日志保存到elasticsearch-6.4.0目录下的data和logs目录</span><br><span class="line"><span class="comment">#path.data: /path/to/data</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Path to log files:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#path.logs: /path/to/logs</span></span><br></pre></td></tr></table></figure></p>
<p>内存大小的设置，根据机器内存大小而设置，一般不超过系统总内存的一半：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearch-6.4.0/config</span><br><span class="line">$ vi jvm.options</span><br><span class="line"></span><br><span class="line">-Xms1g</span><br><span class="line">-Xmx1g</span><br></pre></td></tr></table></figure></p>
<p>启动<code>elasticsearch</code>：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearch-6.4.0/bin</span><br><span class="line">$ ./elasticsearch</span><br></pre></td></tr></table></figure></p>
<p>我们也可以在启动的时候加上参数<code>-d</code>，以后台运行方式启动：<code>./elasticsearch -d</code>。这样单节点版本的<code>elasticsearch</code>就安装完了，在浏览器中输入如下地址：<a href="http://localhost:9200/" target="_blank" rel="noopener">http://localhost:9200/</a></p>
<pre><code>{
&quot;name&quot; : &quot;node-1&quot;,
  &quot;cluster_name&quot; : &quot;hewentian-cluster&quot;,
  &quot;cluster_uuid&quot; : &quot;ihLk1iOlTEis2PkQrLhmLQ&quot;,
  &quot;version&quot; : {
    &quot;number&quot; : &quot;6.4.0&quot;,
    &quot;build_flavor&quot; : &quot;default&quot;,
    &quot;build_type&quot; : &quot;tar&quot;,
    &quot;build_hash&quot; : &quot;595516e&quot;,
    &quot;build_date&quot; : &quot;2018-08-17T23:18:47.308994Z&quot;,
    &quot;build_snapshot&quot; : false,
    &quot;lucene_version&quot; : &quot;7.4.0&quot;,
    &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,
    &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;
  },
  &quot;tagline&quot; : &quot;You Know, for Search&quot;
}
</code></pre><p>如果你见到上面的输出，证明安装成功了。</p>
<p>不过，你在安装的过程中，有可能会遇到下面的问题之一：</p>
<pre><code>ERROR: [3] bootstrap checks failed
[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]
[2]: max number of threads [2048] for user [hewentian] is too low, increase to at least [4096]
[3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
</code></pre><p>解决方法如下，就算它不报上面的错误，我们也应该根据机器的性能，对下面的选项作相应配置（下面是根据我机器的情况作的配置）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ su root			<span class="comment"># 必须在 root 下才有权限修改系统配置文件</span></span><br><span class="line">Password: </span><br><span class="line">$ vi /etc/security/limits.conf	<span class="comment"># 添加如下配置</span></span><br><span class="line">* soft nofile 65536		<span class="comment"># 上面第一个错误有提示</span></span><br><span class="line">* hard nofile 131072		<span class="comment"># 一般为 soft nofile 的2倍</span></span><br><span class="line">* soft nproc 4096		<span class="comment"># 这个设置线程数</span></span><br><span class="line">* hard nproc 8192</span><br><span class="line"></span><br><span class="line">$ vi /etc/sysctl.conf		<span class="comment"># 添加如下配置</span></span><br><span class="line">vm.max_map_count=262144</span><br><span class="line"></span><br><span class="line">$ sysctl -p			<span class="comment"># 最后执行这个命令，你会见到如下输出</span></span><br><span class="line">vm.max_map_count=262144</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">exit</span>				<span class="comment"># 退出 root</span></span><br></pre></td></tr></table></figure></p>
<h4 id="elasticsearch-head的安装"><a href="#elasticsearch-head的安装" class="headerlink" title="elasticsearch-head的安装"></a>elasticsearch-head的安装</h4><p>为了更方便的与elasticsearch交互，我们还要安装<code>elasticsearch-head</code>插件，安装步骤如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/gitHub</span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/mobz/elasticsearch-head.git</span><br><span class="line">$ <span class="built_in">cd</span> elasticsearch-head</span><br><span class="line">$ npm install 		<span class="comment"># 这个安装过程可能会报错，但是一般不影响。安装完之后，运行下面的命令即可</span></span><br><span class="line">$ npm run start 	<span class="comment"># 运行此命令，你会看到如下输出</span></span><br><span class="line"></span><br><span class="line">&gt; elasticsearch-head@0.0.0 start /home/hewentian/ProjectD/gitHub/elasticsearch-head</span><br><span class="line">&gt; grunt server</span><br><span class="line"></span><br><span class="line">Running <span class="string">"connect:server"</span> (connect) task</span><br><span class="line">Waiting forever...</span><br><span class="line">Started connect web server on http://localhost:9100</span><br><span class="line"></span><br><span class="line">也可以使用下面这种方式启动</span><br><span class="line">$ nohup npm run start &amp;</span><br></pre></td></tr></table></figure></p>
<p>安装结束之后，可以试着打开这个连接：<a href="http://localhost:9100/" target="_blank" rel="noopener">http://localhost:9100/</a><br>这个连接可以打开，就证明<code>elasticsearch-head</code>安装成功，但是你可能会发现，它无法连上<code>elasticsearch</code>。因为，我们还没有对<code>elasticsearch</code>进行设置：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearch-6.4.0/config</span><br><span class="line">$ vi elasticsearch.yml 	<span class="comment"># 增加下面的配置</span></span><br><span class="line"></span><br><span class="line">允许跨域，否则 elasticsearch head 不能访问 elasticsearch</span><br><span class="line">http.cors.enabled: <span class="literal">true</span></span><br><span class="line">http.cors.allow-origin: <span class="string">"*"</span></span><br></pre></td></tr></table></figure></p>
<p>配置好之后，重启<code>elasticsearch</code>，就可以使用<code>elasticsearch-head</code>访问<code>elasticsearch</code>了，如下图所示：<br><img src="/img/elasticsearch-head.png" alt="" title="elasticsearch-head"></p>
<h3 id="elasticsearch使用示例"><a href="#elasticsearch使用示例" class="headerlink" title="elasticsearch使用示例"></a>elasticsearch使用示例</h3><p>使用示例我不打算自已写，因为<code>elasticsearch</code>官方的<code>README.textile</code>已经写得非常详细了。下面的示例摘自<code>elasticsearch-6.4.0/README.textile</code>：<br><strong>下面代码的缩进尽量不要使用tab，要使用空格</strong></p>
<h4 id="Indexing"><a href="#Indexing" class="headerlink" title="Indexing"></a>Indexing</h4><p>Let’s try and index some twitter like information. First, let’s index some tweets (the @twitter@ index will be created automatically):</p>
<pre>
curl -XPUT 'http://localhost:9200/twitter/doc/1?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T13:12:00",
    "message": "Trying out Elasticsearch, so far so good?"
}'

curl -XPUT 'http://localhost:9200/twitter/doc/2?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T14:12:12",
    "message": "Another tweet, will it be indexed?"
}'

curl -XPUT 'http://localhost:9200/twitter/doc/3?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "elastic",
    "post_date": "2010-01-15T01:46:38",
    "message": "Building the site, should be kewl"
}'
</pre>


<h4 id="Getting"><a href="#Getting" class="headerlink" title="Getting"></a>Getting</h4><p>Now, let’s see if the information was added by GETting it:</p>
<pre>
curl -XGET 'http://localhost:9200/twitter/doc/1?pretty=true'
curl -XGET 'http://localhost:9200/twitter/doc/2?pretty=true'
curl -XGET 'http://localhost:9200/twitter/doc/3?pretty=true'

</pre>

<p>The results show below:</p>
<pre>
{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "1",
  "_version" : 1,
  "found" : true,
  "_source" : {
    "user" : "kimchy",
    "post_date" : "2009-11-15T13:12:00",
    "message" : "Trying out Elasticsearch, so far so good?"
  }
}

{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "2",
  "_version" : 1,
  "found" : true,
  "_source" : {
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "Another tweet, will it be indexed?"
  }
}

{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "3",
  "_version" : 1,
  "found" : true,
  "_source" : {
    "user" : "elastic",
    "post_date" : "2010-01-15T01:46:38",
    "message" : "Building the site, should be kewl"
  }
}
</pre>


<h4 id="Updating"><a href="#Updating" class="headerlink" title="Updating"></a>Updating</h4><p>The updating operation is the same as Indexing.</p>
<pre>
curl -XPUT 'http://localhost:9200/twitter/doc/1?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T13:12:00",
    "message": "Trying out Elasticsearch, so far so good? yes"
}'

{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "1",
  "_version" : 2,
  "result" : "updated",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 1,
  "_primary_term" : 1
}
</pre>


<h4 id="Deleting"><a href="#Deleting" class="headerlink" title="Deleting"></a>Deleting</h4><p>The deleting operation is also easy.</p>
<pre>
curl -XDELETE 'http://localhost:9200/twitter/doc/1'

{"_index":"twitter","_type":"doc","_id":"1","_version":3,"result":"deleted","_shards":{"total":2,"successful":1,"failed":0},"_seq_no":2,"_primary_term":1}
</pre>

<h4 id="Searching"><a href="#Searching" class="headerlink" title="Searching"></a>Searching</h4><p>Mmm search…, shouldn’t it be elastic?<br>Let’s find all the tweets that @kimchy@ posted:</p>
<pre>
curl -XGET 'http://localhost:9200/twitter/_search?q=user:kimchy&pretty=true'

{
  "took" : 42,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 2,
    "max_score" : 0.2876821,
    "hits" : [
      {
        "_index" : "twitter",
        "_type" : "doc",
        "_id" : "2",
        "_score" : 0.2876821,
        "_source" : {
          "user" : "kimchy",
          "post_date" : "2009-11-15T14:12:12",
          "message" : "Another tweet, will it be indexed?"
        }
      },
      {
        "_index" : "twitter",
        "_type" : "doc",
        "_id" : "1",
        "_score" : 0.2876821,
        "_source" : {
          "user" : "kimchy",
          "post_date" : "2009-11-15T13:12:00",
          "message" : "Trying out Elasticsearch, so far so good?"
        }
      }
    ]
  }
}
</pre>

<p>We can also use the JSON query language Elasticsearch provides instead of a query string:</p>
<pre>
curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '
{
    "query" : {
        "match" : { "user": "kimchy" }
    }
}'
</pre>

<p>Just for kicks, let’s get all the documents stored (we should see the tweet from @elastic@ as well):</p>
<pre>
curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '
{
    "query" : {
        "match_all" : {}
    }
}'
</pre>

<p>We can also do range search (the @post_date@ was automatically identified as date)</p>
<pre>
curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '
{
    "query" : {
        "range" : {
            "post_date" : { "from" : "2009-11-15T13:00:00", "to" : "2009-11-15T14:00:00" }
        }
    }
}'
</pre>

<p>There are many more options to perform search, after all, it’s a search product no? All the familiar Lucene queries are available through the JSON query language, or through the query parser.</p>
<h4 id="Multi-Tenant-Indices-and-Types"><a href="#Multi-Tenant-Indices-and-Types" class="headerlink" title="Multi Tenant - Indices and Types"></a>Multi Tenant - Indices and Types</h4><p>Man, that twitter index might get big (in this case, index size == valuation). Let’s see if we can structure our twitter system a bit differently in order to support such large amounts of data.</p>
<p>Elasticsearch supports multiple indices. In the previous example we used an index called @twitter@ that stored tweets for every user.</p>
<p>Another way to define our simple twitter system is to have a different index per user (note, though that each index has an overhead). Here is the indexing curl’s in this case:</p>
<pre>
curl -XPUT 'http://localhost:9200/kimchy/doc/1?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T13:12:00",
    "message": "Trying out Elasticsearch, so far so good?"
}'

curl -XPUT 'http://localhost:9200/kimchy/doc/2?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T14:12:12",
    "message": "Another tweet, will it be indexed?"
}'
</pre>

<p>The above will index information into the @kimchy@ index. Each user will get their own special index.</p>
<p>Complete control on the index level is allowed. As an example, in the above case, we would want to change from the default 5 shards with 1 replica per index, to only 1 shard with 1 replica per index (== per twitter user). Here is how this can be done (the configuration can be in yaml as well):</p>
<pre>
curl -XPUT http://localhost:9200/another_user?pretty -H 'Content-Type: application/json' -d '
{
    "index" : {
        "number_of_shards" : 1,
        "number_of_replicas" : 1
    }
}'
</pre>

<p>Search (and similar operations) are multi index aware. This means that we can easily search on more than one<br>index (twitter user), for example:</p>
<pre>
curl -XGET 'http://localhost:9200/kimchy,another_user/_search?pretty=true' -H 'Content-Type: application/json' -d '
{
    "query" : {
        "match_all" : {}
    }
}'
</pre>

<p>Or on all the indices:</p>
<pre>
curl -XGET 'http://localhost:9200/_search?pretty=true' -H 'Content-Type: application/json' -d '
{
    "query" : {
        "match_all" : {}
    }
}'
</pre>

<p>{One liner teaser}: And the cool part about that? You can easily search on multiple twitter users (indices), with different boost levels per user (index), making social search so much simpler (results from my friends rank higher than results from friends of my friends).</p>
<h4 id="Cat-Index"><a href="#Cat-Index" class="headerlink" title="Cat Index"></a>Cat Index</h4><pre>
curl -XGET 'http://localhost:9200/_cat/indices?v'

health status index   uuid                   pri rep docs.count docs.deleted store.size pri.store.size
yellow open   twitter 1aZo0hSfRkKG1INAEZgpnQ   5   1          2            0       14kb           14kb
yellow open   music   ytI7cirvQXOi1hsrvAMGGA   5   1          0            0      1.2kb          1.2kb
</pre>



      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/09/16/elasticsearch-install/" data-id="cjmx9poc00008vt2i9megyvij" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-redis-note" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/12/redis-note/" class="article-date">
  <time datetime="2018-09-12T00:54:32.000Z" itemprop="datePublished">2018-09-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/12/redis-note/">redis 学习笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>首先，你必须有一台<code>redis</code>服务器可以使用，如果还没安装，可以参考我的上一篇 <a href="../../../../2018/08/07/redis-install/">redis 的安装使用</a></p>
<p>使用JAVA API来操作Redis的例子可以在这里找到：<a href="https://github.com/hewentian/studyResource/blob/master/src/main/java/com/hewentian/util/RedisUtil.java">RedisUtil.java</a>、<a href="https://github.com/hewentian/studyResource/blob/master/src/main/java/com/hewentian/redis/RedisDemo.java">RedisDemo.java</a></p>
<p>部分笔记摘自《Redis 实战》，它总结得很好。</p>
<p>Redis默认16个数据库，并以数字为索引，从0开始到15，可以手工修改这个配置，增加数量。登录的时候，默认为0库。</p>
<h4 id="Redis与其他数据库的对比"><a href="#Redis与其他数据库的对比" class="headerlink" title="Redis与其他数据库的对比"></a>Redis与其他数据库的对比</h4><p>  高性能键值缓存服务器<code>memcached</code>也经常被拿来与<code>Redis</code>进行比较：这两者都可以用于存储键值映射，彼此的性能也相关无几，但是<code>Redis</code>能够自动以两种不同的方式将数据写入硬盘，并且<code>Redis</code>除了能存储普通的字符串之外，还可以存储其他4种数据结构，而<code>memcached</code>只能存储普通的字符串键。这些不同之处使得<code>Redis</code>可以用于解决更为广泛的问题，并且既可以用作主数据库(primary database)使用，又可以作为其他存储系统的辅助数据库(auxiliary database)使用。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th style="text-align:left">类型</th>
<th style="text-align:left">数据存储选项</th>
<th style="text-align:left">查询类型</th>
<th style="text-align:left">附加功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>Redis</td>
<td style="text-align:left">使用内存存储的非关系数据库</td>
<td style="text-align:left">字符串、列表、集合、散列表、有序集合</td>
<td style="text-align:left">每种数据类型都有自已的专属命令，另外还有批量操作(bulk operation)和不完全(partial)的事务支持</td>
<td style="text-align:left">发布与订阅，主从复制(master/slave replication)，持久化，脚本(存储过程，stored procedure)</td>
</tr>
<tr>
<td>memcached</td>
<td style="text-align:left">使用内存存储的键值缓存</td>
<td style="text-align:left">键值之间的映射</td>
<td style="text-align:left">创建命令、读取命令、更新命令、删除命令以及其他几个命令</td>
<td style="text-align:left">为提升性能而设的多线程服务器</td>
</tr>
<tr>
<td>Mysql</td>
<td style="text-align:left">关系数据库</td>
<td style="text-align:left">每个数据库可以包含多个表，每个表可以包含多个行；可以处理多个表的视图(view)；支持空间(spatial)和第三方扩展</td>
<td style="text-align:left">SELECT、INSERT、UPDATE、DELETE、函数、存储过程</td>
<td style="text-align:left">支持ACID性质(需要使用InnoDB)，主从复制，主主复制(master/master replication)</td>
</tr>
<tr>
<td>PostgreSQL</td>
<td style="text-align:left">关系数据库</td>
<td style="text-align:left">每个数据库可以包含多个表，每个表可以包含多个行；可以处理多个表的视图(view)；支持空间(spatial)和第三方扩展；支持可定制类型</td>
<td style="text-align:left">SELECT、INSERT、UPDATE、DELETE、内置函数、自定义存储过程</td>
<td style="text-align:left">支持ACID性质，主从复制，由第三方支持的多主复制(multi-master replication)</td>
</tr>
<tr>
<td>MongoDB</td>
<td style="text-align:left">使用硬盘存储的非关系文档存储</td>
<td style="text-align:left">每个数据库可以包含多个表，每个表可以包含多个无schema(schema-less)的BSON文档</td>
<td style="text-align:left">创建命令、读取命令、更新命令、删除命令、条件查询命令等</td>
<td style="text-align:left">支持 map-reduce 操作，主从复制，分片，空间索引(spatial index)</td>
</tr>
</tbody>
</table>
<h4 id="Redis提供的5种结构"><a href="#Redis提供的5种结构" class="headerlink" title="Redis提供的5种结构"></a>Redis提供的5种结构</h4><table>
<thead>
<tr>
<th>结构类型</th>
<th style="text-align:left">结构存储的值</th>
<th style="text-align:left">结构的读写能力</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td style="text-align:left">可以是字符串、整数或者浮点数</td>
<td style="text-align:left">对整个字符串或者字符串的其中一部分执行操作，对整数和浮点数执行自增或者自减操作</td>
</tr>
<tr>
<td>LIST</td>
<td style="text-align:left">一个链表，链表上的每个节点都包含了一个字符串</td>
<td style="text-align:left">从链表的两端推入或者弹出元素；根据偏移量对链表进行修剪；读取单个或者多个元素；根据值查找或者移除元素</td>
</tr>
<tr>
<td>SET</td>
<td style="text-align:left">包含字符串的无序收集器，并且被包含的每个字符串都是独一无二、各不相同的</td>
<td style="text-align:left">添加、获取、移除单个元素；检查一个元素是否存在于集合中；计算交集、并集、差集；从集合里面随机获取元素</td>
</tr>
<tr>
<td>HASH</td>
<td style="text-align:left">包含键值对的无序散列表</td>
<td style="text-align:left">添加、获取、移除单个键值对；获取所有键值对</td>
</tr>
<tr>
<td>ZSET(有序集合)</td>
<td style="text-align:left">字符串成员与浮点数分值之间的有序映射，元素的排列顺序由分值的大小决定</td>
<td style="text-align:left">添加、获取、删除单个元素；根据分值范围或者成员来获取元素</td>
</tr>
</tbody>
</table>
<p>  在实际中最好还是让主服务器只使用50%~65%的内存，留下30%~45%的内存用于执行BGSAVE命令和创建记录写命令的缓冲区。</p>
<p>  当所有成员的分值都相同时，有序集合将根据成员的名字来进行排序；而当所有成员的分值都是0的时候，成员将按照字符串的二进制顺序进行排序。</p>
<p>  对于大部分数据库来说，插入行操作的执行速度非常快（插入行只会在硬盘文件末尾进行写入）。不过，对表里面的行进行更新却是一个速度相当慢的操作，因为这种更新除了会引起一次随机读(random read)之外，还可能会引起一次随机写(random write)。</p>
<p>使用cookie实现购物车–也就是将整个购物车都存储到cookie里面的做法非常常见，这种做法的一大优点是无须对数据库进行写入就可以实现购物车功能，而缺点则是程序需要重新解析和验证cookie，确保cookie的格式正确，并且包含的商品都是真正可购买的商品。cookie购物车还有一个缺点：因为浏览器每次发送请求都会连cookie一起发送，所以如果购物车cookie的体积比较大，那么请求发送和处理的速度可能会有所降低。</p>
<p>如果用户对一个不存在的键或者一个保存了空串的键执行自增或者自减操作，那么Redis在执行操作时会将这个键的值当作是0来处理。如果用户尝试对一个值无法被解释为整数或者浮点数的字符串键执行自增或者自减操作，那么Redis将向用户返回一个错误。</p>
<p>Redis不支持嵌套结构特性</p>
<h4 id="Redis的基本事务"><a href="#Redis的基本事务" class="headerlink" title="Redis的基本事务"></a>Redis的基本事务</h4><p>  Redis的基本事务(basic transaction)需要用到MULTI命令和EXEC命令，这种事务可以让一个客户端在不被其他客户端打断的情况下执行多个命令。和关系数据库那种可以在执行的过程中进行回滚(rollback)的事务不同，在Redis里面，被MULTI命令和EXEC命令包围的所有命令会一个接一个地执行，直到所有命令都执行完毕为止。当一个事务执行完毕之后，Redis才会处理其他客户端的命令。<br>  要在Redis里面执行事务，我们首先需要执行MULTI命令，然后输入那些我们想要在事务里面执行的命令，最后再执行EXEC命令。当Redis从一个客户端那里接收到MULTI命令时，Redis会将这个客户端之后发送的所有命令都放入到一个队列里面，直到这个客户端发送EXEC命令为止，然后Redis就会在不被打断的情况下，一个接一个地执行存储在队列里面的命令。从语义上来说，Redis事务在Python客户端上面是由流水线(pipeline)实现的：对连接对象调用pipeline()方法将创建一个事务，在一切正常的情况下，客户端会自动地使用MULTI和EXEC包裹起用户输入的多个命令。此外，为了减少Redis与客户端之间的通信往返次数，提升执行多个命令时的性能，Python的Redis客户端会存储起事务包含的多个命令，然后在事务执行时一次性地将所有命令都发送给Redis。</p>
<h4 id="持久化选项"><a href="#持久化选项" class="headerlink" title="持久化选项"></a>持久化选项</h4><p>  Redis提供了两种不同的持久化方法来将数据存储到硬盘里面。一种方法叫快照(snapshotting)，它可以将存在于某一时刻的所有数据都写入硬盘里面。另一种方法叫只追加文件(append-only file, AOF)，它会在执行写命令时，将被执行的写命令复制到硬盘里面。这两种持久化方法既可以同时使用，又可以单独使用，在某些情况下甚至可以两种方法都不使用。<br>  为了防止Redis因为创建子进程而出现停顿，我们可以考虑关闭自动保存，转而通过手动发送BGSAVE或者SAVE来进行持久化。手动发送BGSAVE一样会引起停顿，唯一不同的是用户可以通过手动发送BGSAVE命令来控制停顿出现的时间。另一方面，虽然SAVE会一直阻塞Redis直到快照生成完毕，但是因为它不需要创建子进程，所以就不会像BGSAVE一样因为创建子进程而导致Redis停顿；并且因为没有子进程在争抢资源，所以SAVE创建快照的速度会比BGSAVE创建快照的速度要来得更快一些。</p>
<h4 id="创建快照的办法有以下几种"><a href="#创建快照的办法有以下几种" class="headerlink" title="创建快照的办法有以下几种"></a>创建快照的办法有以下几种</h4><ol>
<li>客户端可以通过向Redis发送BGSAVE命令来创建一个快照；</li>
<li>客户端还可以通过向Redis发送SAVE命令来创建一个快照，接到SAVE命令的Redis服务器在快照创建完毕之前将不再响应任何其他命令；</li>
<li>用户设置save配置选项；</li>
<li>当Redis通过SHUTDOWN命令接收到关闭服务器的请求时，或者接收到标准TERM信号时，会执行一个SAVE命令；</li>
<li>当一个Redis服务器连接另一个Redis服务器，并向对方发送SYNC命令来开始一次复制操作的时候，如果主服务器目前没有在执行BGSAVE操作，或者主服务器并非刚刚执行完BGSAVE操作，那么主服务器就会执行BGSAVE命令。</li>
</ol>
<p>在只使用快照持久化来保存数据时，一定要记住：如果系统真的发生崩溃，用户将丢失最近一次生成快照之后更改的所有数据。因此，快照持久化只适用于那些即使丢失一部分数据也不会造成问题的应用程序。</p>
<p>  当Redis存储的数据量只有几个GB的时候，使用快照来保存数据是没有问题的。Redis会创建子进程并将数据保存到硬盘里面，生成快照所需的时间比你读这句话所需的时间还要短。但随着Redis占用的内存越来越多，BGSAVE在创建子进程时耗费的时间也会越来越多。如果Redis的内存占用量达到数十个GB，并且剩余的空闲内存并不多，或者Redis运行在虚拟机上面，那么执行BGSAVE可能会导致系统长时间地停顿，也可能引发系统大量地使用虚拟内存，从而导致Redis的性能降低至无法使用的程度。</p>
<p>  AOF持久化会将被执行的写命令写到AOF文件的末尾，以此来记录数据发生的变化。因此，Redis只要从头到尾重新执行一次AOF文件包含的所有写命令，就可以恢复AOF文件所记录的数据集。通过<code>appendonly yes</code>配置选项来打开。</p>
<p>  Redis每秒同步一次AOF文件时的性能和不使用任何持久化特性时的性能相关无几，而通过每秒同步一次AOF文件，Redis可以保证，即使出现系统崩溃，用户也最多只会丢失一秒之内产生的数据。</p>
<p>  因为Redis会不断地将被执行的写命令记录到AOF文件里面，所以随着Redis不断运行，AOF文件的体积也会不断增长，在极端情况下，体积不断增大的AOF文件甚至可能会用完硬盘的所有可用空间。还有另一个问题就是，因为Redis在重启之后需要通过重新执行AOF文件记录的所有写命令来还原数据集，所以如果AOF文件的体积非常大，那么还原操作执行的时间就可能会非常长。为了解决AOF文件体积不断增大的问题，用户可以向Redis发送BGREWRITEAOF命令，这个命令会通过移除AOF文件中的冗余命令来重写(rewrite)AOF文件，使AOF文件的体积变得尽可能地小。</p>
<p>  关系数据库通常会使用一个主服务器(master)向多个从服务器(slave)发送更新，并使用从服务器来处理所有读请求。在Redis中开启从服务器所必须的选项只有<code>slaveof</code>一个。通过向从服务器发送<code>SLAVEOF no one</code>命令，我们可以让这个从服务器断开与主服务器的连接。因为Redis的主服务器和从服务器并没有特别不同的地方，所以从服务器也可以拥有自已的从服务器，并由此形成主从链(master/slave chaining)，如下图：<br><img src="/img/redis-master-slave-chaining.png" alt=""></p>
<p>  解决从服务器重同步(resync)问题的其中一个方法，就是减少主服务器需要传送给从服务器的数据数量，这可以通过构建像上图所示的树状复制中间层来完成。除了构建树状的从服务器群组之外，解决从服务器重同步问题的另一个方法就是对网络连接进行压缩，从而减少需要传送的数据量。一些Redis用户就发现使用带压缩的SSH隧道(tunnel)进行连接可以明显地降低带宽占用，如果使用这个方法，记得使用SSH提供的选项来让SSH连接在断线后自动进行连接。</p>
<p>  提升Redis读取能力的最简单方法，就是添加只读从服务器。在使用只读从服务器的时候，请务必记得只对Redis主服务器进行写入。在默认情况下，尝试对一个被配置为从服务器的Redis服务器进行写入将引发一个错误（就算这个从服务器是其他从服务器的主服务器，也是如此）。不过，可以通过设置配置选项使从服务器也能执行写入操作，不过由于这一功能通常都处于关闭状态，所以对从服务器进行写入一般都会引发错误。使用多个Redis从服务器处理读查询时可能会遇到的最棘手的问题，就是主服务器临时下线或者永久下线。</p>
<p>  Redis Sentinel可以配合Redis的复制功能使用，并对下线的主服务器进行故障转移。</p>
<h4 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h4><p>  一般来说，在对数据进行“加锁”时，程序首先需要通过获取(acquire)锁来得到对数据进行排他性访问的能力，然后才能对数据进行一系列的操作，最后还要将锁释放(release)给其他程序。对于能够被多个线程访问的共享内存数据结构来说，这种“先获取锁，然后执行操作，最后释放锁”的动作非常常见。Redis使用WATCH命令来代替对数据进行加锁，因为WATCH只会在数据被其他客户端抢先修改了的情况下通知执行了这个命令的客户端，而不会阻止其他客户端对数据进行修改，所以这个命令被称为乐观锁(optimistic locking)。</p>
<p>  分布式锁也有类似的“首先获取锁，然后执行操作，最后释放锁”动作，但这种锁既不是给同一个进程中的多个线程使用，也不是给同一台机器上的多个进程使用，而是由不同机器上的不同Redis客户端进行获取和释放锁的。</p>
<p>  我们没有直接使用操作系统级别的锁、编程语言级别的锁，或者其他各式各样的锁，而是选择了花费大量时间去使用Redis构建锁，这其中一个原因和范围有关：为了对Redis存储的数据进行排他性访问，客户端需要访问一个锁，这个锁必须定义在一个可以让所有客户端都看得见的范围之内，而这个范围就是Redis本身，因此我们需要把锁构建在Redis里面。另一方面，虽然Redis提供SETNX命令确实具有基本的加锁功能，但它的功能并不完整，并且也不具备分布式锁常见的一些高级特性，所以我们还是需要自已动手来构建分布式锁。</p>
<p>  WATCH、MULTI和EXEC组成的事务并不具有可扩展性，原因在于程序在尝试完成一个事务的时候，可能会因为事务执行失败而反复地进行重试。保证数据的正确性是一件非常重要的事情，但使用WATCH命令的做法并不完美 。为了解决这个问题，我们将使用锁。</p>
<p>  因为客户端即使在使用锁的过程中也可能会因为这样或那样的原因而下线，所以为了防止客户端在取得锁之后崩溃，并导致锁一直处于“已被获取”的状态，最终版的锁实现将带有超时限制特性：如果获得锁的进程未能在指定的时限内完成操作，那么锁将自动被释放。下面列出了一些导致锁出现不正确实行为的原因，也及锁在不正确运行时的症状：</p>
<ol>
<li>持有锁的进程因为操作时间过长而导致锁被自动释放，但进程本身并不知晓这一点，甚至还可能会错误地释放掉了其他进程持有的锁；</li>
<li>一个持有锁并打算执行长时间操作的进程已经崩溃，但其他想要获取锁的进程不知道哪个进程持有着锁，也无法检测出持有锁的进程已经崩溃，只能白白地浪费时间等待锁被释放；</li>
<li>在一个进程持有的锁过期之后，其他多个进程同时尝试去获取锁，并且都获得了锁；</li>
<li>上面提到的第一种情况和第三种情况同时出现，导致有多个进程获得了锁，而每个进程都以为自已是唯一一个获得锁的进程。</li>
</ol>
<p>在高负载情况下，使用锁可以减少重试次数、降低延迟时间、提升性能并将加锁的粒度调整至合适的大小。</p>
<p>一般来说，当程序使用一个来自Redis的值去构建另一个将要被添加到Redis里面的值时，就需要使用锁或者由WATCH、MULTI和EXEC组成的事务来消除竞争条件。</p>
<h4 id="计数信号量"><a href="#计数信号量" class="headerlink" title="计数信号量"></a>计数信号量</h4><p>  计数信号量是一种锁，它可以让用户限制一项资源最多能够同时被多少个进程访问，通常用于限定能够同时使用的资源数量。你可以把我们在前一节创建的锁看作是只能被一个进程访问的信号量。计数信号量和其他锁的区别在于，当客户端获取锁失败的时候，客户端通常会选择进行等待；而当客户端获取计数信号量失败的时候，客户端通常会选择立即返回失败结果。</p>
<p>  以下是之前介绍过的各个信号量实现的优缺点：</p>
<ol>
<li>如果你对于使用系统时钟没有意见，也不需要对信号量进行刷新，并且能够接受信号量的数量偶尔超过限制，那么可以使用我们给出的第一个信号量实现；</li>
<li>如果你只信任差距在一两秒之间的系统时钟，但仍然能够接受信号量的数量偶尔超过限制，那么你可以使用第二个信号量实现；</li>
<li>如果你希望信号量一直都具有正确的行为，那么可以使用带锁的信号量实现来保证正确性。</li>
</ol>
<h4 id="消息拉取"><a href="#消息拉取" class="headerlink" title="消息拉取"></a>消息拉取</h4><p>  两个或多个客户端在互相发送和接收消息的时候，通常会使用以下两种方法来传递消息。第一种被称为消息推送(push messaging)，也就是由发送者来确保所有接收者已经成功接收到了消息。Redis内置了用于进行消息推送的PUBLISH命令和SUBSCRIBE命令。这两个命令有个缺陷：客户端必须一直在线才能接收到消息，断线可能会导致客户端丢失消息。第二种方法被称为消息拉取(pull messaging)，这种方法要求接收者自已去获取存储在某种邮箱(mailbox)里面的消息。</p>
<h4 id="索引相关"><a href="#索引相关" class="headerlink" title="索引相关"></a>索引相关</h4><p>  从文档里面提取单词的过程通常被称为语法分析(parsing)和标记化(tokenization)，这个过程可以产生出一系列用于标识文档的标记(token)，标记有时候又被称为单词(word)。标记化的一个常见的附加步骤，就是移除内容中的非用词(stop word)。非用词就是那些在文档中频繁出现但是却没有提供相应信息量的单词，对这些单词进行搜索将返回大量无用的结果。移除非用词不仅可以提高搜索性能，还可以减少索引的体积。<br>  用户有些时候可能会想要使用多个具有相同意思的单词进行搜索，并把它们看作是同一个单词，我们把这样的单词称为同义词。<br>  搜索程序在取得多个文档之后，通常还需要根据每个文档的重要性对它们进行排序–搜索领域把这一问题称为关联度计算问题。</p>
<h4 id="广告相关"><a href="#广告相关" class="headerlink" title="广告相关"></a>广告相关</h4><p>  广告索引操作的特别之处在于它返回的不是一组广告或者一组搜索结果，而是单个广告；并且被索引的广告通常都拥有像位置、年龄或者性别这类必须的定向参数。</p>
<p>  Web页面上展示的广告主要有3种类型：按展示次数计费(cost per view)、按点击次数计费(cost per click)和按动作执行次数计费(cost per action)。按展示次数计费的广告又称为CPM广告或按千次计费(cost per mile)广告，这种广告每展示1000次就需要收取固定的费用。按点击计费的广告又称为CPC广告，这种广告根据被点击的次数收取固定的费用。按动作执行次数计费的广告又称为CPA广告，这种广告根据用户在广告的目的地网站上执行的动作收取不同的费用。</p>
<p>  让广告的价格保持一致：为了尽可能地简化广告价格的计算方式，程序将对所有类型的广告进行转换，使得它们的价格可以基于每千次展示进行计算，产生出一个估算CPM(estimated CPM)，简称eCPM。对于CPM广告来说，因为这种广告已经给出了CPM价格，所以程序只要直接把它的CPM用作eCPM就可以了。至于CPC广告和CPA广告，程序则需要根据相应的规则为它们计算出eCPM。</p>
<h4 id="优化Redis"><a href="#优化Redis" class="headerlink" title="优化Redis"></a>优化Redis</h4><p>  降低Redis的内存占用有助于减少创建快照和加载快照所需的时间、提升载入AOF文件和重写AOF文件时的效率、缩短从服务器进行同步所需的时间，并且能让Redis存储更多的数据而无需添加额外的硬件。</p>
<p>  在列表、散列和有序集合的长度较短或者体积较小的时候，Redis可以选择使用一种名为压缩列表(ziplist)的紧凑存储方式来存储这些结构。压缩列表会以序列化的方式存储数据，这些序列化数据每次被读取的时候都要进行解码，每次被写入的时候也要进行局部的重新编码，并且可能需要对内存里面的数据进行移动。</p>
<h4 id="不同结构关于使用压缩列表表示的配置选项（我安装的是-4-0-11-版本），配置文件位于-REDIS-HOME-redis-conf"><a href="#不同结构关于使用压缩列表表示的配置选项（我安装的是-4-0-11-版本），配置文件位于-REDIS-HOME-redis-conf" class="headerlink" title="不同结构关于使用压缩列表表示的配置选项（我安装的是 4.0.11 版本），配置文件位于{REDIS_HOME}/redis.conf"></a>不同结构关于使用压缩列表表示的配置选项（我安装的是 4.0.11 版本），配置文件位于<code>{REDIS_HOME}/redis.conf</code></h4><pre><code># Hashes are encoded using a memory efficient data structure when they have a
# small number of entries, and the biggest entry does not exceed a given
# threshold. These thresholds can be configured using the following directives.
hash-max-ziplist-entries 512
hash-max-ziplist-value 64

# Lists are also encoded in a special way to save a lot of space.
# The number of entries allowed per internal list node can be specified
# as a fixed maximum size or a maximum number of elements.
# For a fixed maximum size, use -5 through -1, meaning:
# -5: max size: 64 Kb  &lt;-- not recommended for normal workloads
# -4: max size: 32 Kb  &lt;-- not recommended
# -3: max size: 16 Kb  &lt;-- probably not recommended
# -2: max size: 8 Kb   &lt;-- good
# -1: max size: 4 Kb   &lt;-- good
# Positive numbers mean store up to _exactly_ that number of elements
# per list node.
# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),
# but if your use case is unique, adjust the settings as necessary.
list-max-ziplist-size -2

# Sets have a special encoding in just one case: when a set is composed
# of just strings that happen to be integers in radix 10 in the range
# of 64 bit signed integers.
# The following configuration setting sets the limit in the size of the
# set in order to use this special memory saving encoding.
set-max-intset-entries 512

# Similarly to hashes and lists, sorted sets are also specially encoded in
# order to save a lot of space. This encoding is only used when the length and
# elements of a sorted set are below the following limits:
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
</code></pre><p>说明：</p>
<ol>
<li>entries选项说明散列、集合和有序集合在被编码为压缩列表的情况下，允许包含的最大元素数量；</li>
<li>value选项则说明了压缩列表每个节点的最大体积是多少个字节；</li>
<li>当上述两个选项的限制条件中的任意一个被突破的时候，Redis就会将相应的列表、散列或是有序集合从压缩列表编码转换为其他结构，而内存占用也会因此而增加；</li>
<li>当压缩列表被转换为普通的结构之后，即使结构将来重新满足配置选项设置的限制条件，结构也不会重新转换回压缩列表；</li>
<li>如果整数包含的所有成员都可以被解释为十进制整数，而这些整数又处于平台的有符号整数范围之内，并且集合成员的数量又足够少的话（上面有配置），那么Redis就会以有序整数数组的方式存储集合，这种存储方式又被称为整数集合(intset)。以有序数组的方式存储集合不仅可以降低内存消耗，还可以提升所有标准集合的执行速度。</li>
</ol>
<p>缺点：读写一个长度较大的压缩列表可能会给性能带来负面的影响，随着紧凑结构的体积变得越来越大，操作这些结构的速度也会变得越来越慢。</p>
<h4 id="让键名保持简短"><a href="#让键名保持简短" class="headerlink" title="让键名保持简短"></a>让键名保持简短</h4><p>  到目前为止尚未提到的一件事，就是减少键长度的作用，这里所说的“键”包括所有数据库键、散列的域、集合和有序集合的成员以及所有列表的节点，键的长度越长，Redis需要存储的数据也就越多。</p>
<h4 id="分片结构"><a href="#分片结构" class="headerlink" title="分片结构"></a>分片结构</h4><p>  分片本质上就是基于某些简单的规则将数据划分为更小的部分，然后根据数据所属的部分来决定将数据发送到哪个位置上面。</p>
<h4 id="使用Lua来扩展Redis"><a href="#使用Lua来扩展Redis" class="headerlink" title="使用Lua来扩展Redis"></a>使用Lua来扩展Redis</h4><p>  使用Lua编程语言进行的服务器端脚本编程功能，这个功能可以让用户直接在Redis内部执行各种操作，从而达到简化代码并提高性能的作用。将脚本载入Redis需要用到一个名为<code>SCRIPT LOAD</code>的命令，这个命令接受一个字符串格式的Lua脚本为参数，它会把脚本存储起来等待之后使用，然后返回被存储脚本的SHA1校验和。之后，用户只要调用<code>EVALSHA</code>命令，并输入脚本的SHA1校验和以及脚本所需的全部参数就可以调用之前存储的脚本。</p>
<p>  Lua版本的锁实现减少了加锁时所需的通信往返次数，所以Lua版本的锁实现在尝试获取锁时的速度比原版的锁要快得多。虽然Lua脚本可以提供巨大的性能优势，并且能在一些情况下大幅地简化代码，但是我们也要记住，运行在Redis内部的Lua脚本只能访问位于Lua脚本之内或者Redis数据库之内的数据，而锁或<code>WATCH/MULTI/EXEC</code>事务并没有这一限制。</p>
<p>  Redis在将数据库持久化到硬盘的时候，需要用到fork系统调用，而Windows并不支持这个调用。在缺少fork调用的情况下，Redis在执行持久化操作期间就只能够阻塞所有客户端，直到持久化操作执行完毕为止。</p>
<p>查看一个对象的类型可以使用<code>DEBUG OBJECT</code>命令</p>
<pre><code>127.0.0.1:6379&gt; rpush test a b c d
(integer) 4
127.0.0.1:6379&gt; DEBUG OBJECT test
Value at:0x7f6160c774e0 refcount:1 encoding:quicklist serializedlength:25 lru:9577083 lru_seconds_idle:44 ql_nodes:1 ql_avg_node:4.00 ql_ziplist_max:-2 ql_compressed:0 ql_uncompressed_size:23
127.0.0.1:6379&gt;
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/09/12/redis-note/" data-id="cjmx9pof00021vt2iqc467m49" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/redis/">redis</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-redis-master-slave" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/14/redis-master-slave/" class="article-date">
  <time datetime="2018-08-14T06:53:19.000Z" itemprop="datePublished">2018-08-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/14/redis-master-slave/">redis 主从配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>要配置主从，我们必须安装两台<code>redis</code>：主服务器为<code>master</code>，从服务器为<code>slave</code>。安装步骤请参考我的上一篇 <a href="../../../../2018/08/07/redis-install/">redis 的安装使用</a></p>
<h3 id="我们在一台机器上面配置主从，多台的配置是一样的，只要修改下IP和PORT即可。以我们上一篇安装好的一台redis为基础，它的安装路径为：-home-hewentian-ProjectD-redis-4-0-11"><a href="#我们在一台机器上面配置主从，多台的配置是一样的，只要修改下IP和PORT即可。以我们上一篇安装好的一台redis为基础，它的安装路径为：-home-hewentian-ProjectD-redis-4-0-11" class="headerlink" title="我们在一台机器上面配置主从，多台的配置是一样的，只要修改下IP和PORT即可。以我们上一篇安装好的一台redis为基础，它的安装路径为：/home/hewentian/ProjectD/redis-4.0.11"></a>我们在一台机器上面配置主从，多台的配置是一样的，只要修改下<code>IP</code>和<code>PORT</code>即可。以我们上一篇安装好的一台<code>redis</code>为基础，它的安装路径为：<code>/home/hewentian/ProjectD/redis-4.0.11</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD</span><br><span class="line">$ mv redis-4.0.11 redis-4.0.11_master</span><br><span class="line">$ cp -r redis-4.0.11_master/ redis-4.0.11_slave/</span><br></pre></td></tr></table></figure>
<p><code>master</code>服务器为：<code>/home/hewentian/ProjectD/redis-4.0.11_master</code><br><code>slave</code>服务器为：<code>/home/hewentian/ProjectD/redis-4.0.11_slave</code></p>
<h3 id="master服务器使用默认端口6379，所以不用配置。下面我们配置slave服务器："><a href="#master服务器使用默认端口6379，所以不用配置。下面我们配置slave服务器：" class="headerlink" title="master服务器使用默认端口6379，所以不用配置。下面我们配置slave服务器："></a><code>master</code>服务器使用默认端口<code>6379</code>，所以不用配置。下面我们配置<code>slave</code>服务器：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/redis-4.0.11_slave/</span><br><span class="line">$ vi redis.conf</span><br><span class="line"></span><br><span class="line">// 将默认端口改为6380，并加上 slaveof 127.0.0.1 6379 和 pidfile，在文件里面改动如下：</span><br><span class="line">port 6380</span><br><span class="line">slaveof 127.0.0.1 6379</span><br><span class="line">pidfile /var/run/redis_6380.pid</span><br></pre></td></tr></table></figure>
<p>保存文件并退出，<code>slave</code>服务器配置完成。</p>
<h3 id="接着我们启动master和slave服务器"><a href="#接着我们启动master和slave服务器" class="headerlink" title="接着我们启动master和slave服务器"></a>接着我们启动<code>master</code>和<code>slave</code>服务器</h3><p>启动<code>master</code>服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/redis-4.0.11_master/src/</span><br><span class="line">$ ./redis-server /home/hewentian/ProjectD/redis-4.0.11_master/redis.conf</span><br></pre></td></tr></table></figure></p>
<p>启动<code>slave</code>服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/redis-4.0.11_slave/src/</span><br><span class="line">$ ./redis-server /home/hewentian/ProjectD/redis-4.0.11_slave/redis.conf</span><br></pre></td></tr></table></figure></p>
<p>在<code>master</code>服务器窗口中，可以看到如下信息：</p>
<pre><code>1514:M 14 Aug 15:58:33.568 * Slave 127.0.0.1:6380 asks for synchronization
1514:M 14 Aug 15:58:33.568 * Full resync requested by slave 127.0.0.1:6380
1514:M 14 Aug 15:58:33.568 * Starting BGSAVE for SYNC with target: disk
1514:M 14 Aug 15:58:33.569 * Background saving started by pid 1584
1584:C 14 Aug 15:58:33.573 * DB saved on disk
1584:C 14 Aug 15:58:33.573 * RDB: 0 MB of memory used by copy-on-write
1514:M 14 Aug 15:58:33.576 * Background saving terminated with success
1514:M 14 Aug 15:58:33.576 * Synchronization with slave 127.0.0.1:6380 succeeded
</code></pre><p>在<code>slave</code>服务器窗口中，可以看到如下信息：</p>
<pre><code>1579:S 14 Aug 15:58:33.567 * Connecting to MASTER 127.0.0.1:6379
1579:S 14 Aug 15:58:33.567 * MASTER &lt;-&gt; SLAVE sync started
1579:S 14 Aug 15:58:33.568 * Non blocking connect for SYNC fired the event.
1579:S 14 Aug 15:58:33.568 * Master replied to PING, replication can continue...
1579:S 14 Aug 15:58:33.568 * Partial resynchronization not possible (no cached master)
1579:S 14 Aug 15:58:33.569 * Full resync from master: 7f883c61e9326b040b150462901e70afd5c4a49c:0
1579:S 14 Aug 15:58:33.576 * MASTER &lt;-&gt; SLAVE sync: receiving 176 bytes from master
1579:S 14 Aug 15:58:33.577 * MASTER &lt;-&gt; SLAVE sync: Flushing old data
1579:S 14 Aug 15:58:33.577 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory
1579:S 14 Aug 15:58:33.577 * MASTER &lt;-&gt; SLAVE sync: Finished with success
</code></pre><p>从上面的信息中，我们可以知道，<code>slave</code>服务器已经连上<code>master</code>服务器。</p>
<h3 id="测试同步数据"><a href="#测试同步数据" class="headerlink" title="测试同步数据"></a>测试同步数据</h3><p>登录<code>master</code>服务器并在其中插入一个键<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/redis-4.0.11_master/src/</span><br><span class="line">$ ./redis-cli -p 6379</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">(empty list or <span class="built_in">set</span>)</span><br><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> name <span class="string">"Tim Ho"</span></span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line"><span class="string">"Tim Ho"</span></span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p>
<p>登录<code>slave</code>服务器并在其中获取一个键<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/redis-4.0.11_slave/src/</span><br><span class="line">$ ./redis-cli -p 6380</span><br><span class="line"></span><br><span class="line">127.0.0.1:6380&gt; keys *</span><br><span class="line">(empty list or <span class="built_in">set</span>)</span><br><span class="line">127.0.0.1:6380&gt; keys *</span><br><span class="line">1) <span class="string">"name"</span></span><br><span class="line">127.0.0.1:6380&gt; get name </span><br><span class="line"><span class="string">"Tim Ho"</span></span><br><span class="line">127.0.0.1:6380&gt;</span><br></pre></td></tr></table></figure></p>
<p>至此，主从配置完成。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/08/14/redis-master-slave/" data-id="cjmx9poev001zvt2ixeb5m3ua" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/redis/">redis</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-redis-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/07/redis-install/" class="article-date">
  <time datetime="2018-08-07T02:50:27.000Z" itemprop="datePublished">2018-08-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/07/redis-install/">redis 的安装使用</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="要使用redis我们首先要安装这个软件。下面，我们说说redis的安装过程："><a href="#要使用redis我们首先要安装这个软件。下面，我们说说redis的安装过程：" class="headerlink" title="要使用redis我们首先要安装这个软件。下面，我们说说redis的安装过程："></a>要使用<code>redis</code>我们首先要安装这个软件。下面，我们说说<code>redis</code>的安装过程：</h4><p>首先，我们要将<code>redis</code>安装包下载回来，截止本文写时，<code>redis</code>官网发布的最新版本为<code>4.0.11</code>。当然，我们也可以从这里下载 <a href="/download/redis-4.0.11.tar.gz">redis-4.0.11.tar.gz</a> 和 <a href="/download/redis-4.0.11.tar.gz.md5">redis-4.0.11.tar.gz.md5</a>。推荐从<code>redis</code>官网下载最新版本。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/</span><br><span class="line">$ wget http://download.redis.io/releases/redis-4.0.11.tar.gz</span><br><span class="line"></span><br><span class="line">// 验证下载文件的完整性，在下载的时候要将MD5文件或者SHA256文件也下载回来</span><br><span class="line">$ md5sum -c redis-4.0.11.tar.gz.md5 </span><br><span class="line">redis-4.0.11.tar.gz: OK</span><br><span class="line"></span><br><span class="line">$ tar xzf redis-4.0.11.tar.gz</span><br><span class="line">$ <span class="built_in">cd</span> redis-4.0.11/</span><br><span class="line">$ make</span><br></pre></td></tr></table></figure>
<h4 id="After-building-Redis-it-is-a-good-idea-to-test-it-using"><a href="#After-building-Redis-it-is-a-good-idea-to-test-it-using" class="headerlink" title="After building Redis, it is a good idea to test it using:"></a>After building Redis, it is a good idea to test it using:</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ make <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line">// 如果见到下面的结果，证明我们已经成功安装</span><br><span class="line">\o/ All tests passed without errors!</span><br></pre></td></tr></table></figure>
<h4 id="下面的内容摘自-REDIS-HOME-README-md"><a href="#下面的内容摘自-REDIS-HOME-README-md" class="headerlink" title="下面的内容摘自${REDIS_HOME}/README.md"></a>下面的内容摘自<code>${REDIS_HOME}/README.md</code></h4><h2 id="Running-Redis"><a href="#Running-Redis" class="headerlink" title="Running Redis"></a>Running Redis</h2><p>To run Redis with the default configuration just type:</p>
<pre><code>$ cd src
$ ./redis-server
</code></pre><p>If you want to provide your redis.conf, you have to run it using an additional<br>parameter (the path of the configuration file):</p>
<pre><code>$ cd src
$ ./redis-server /path/to/redis.conf
</code></pre><p>It is possible to alter the Redis configuration by passing parameters directly<br>as options using the command line. Examples:</p>
<pre><code>$ ./redis-server --port 9999 --slaveof 127.0.0.1 6379
$ ./redis-server /etc/redis/6379.conf --loglevel debug
</code></pre><p>All the options in redis.conf are also supported as options using the command<br>line, with exactly the same name.</p>
<h2 id="Playing-with-Redis"><a href="#Playing-with-Redis" class="headerlink" title="Playing with Redis"></a>Playing with Redis</h2><p>You can use redis-cli to play with Redis. Start a redis-server instance,<br>then in another terminal try the following:</p>
<pre><code>$ cd src
$ ./redis-cli    # 如果需要连接到指定的redis可以使用：-h {IP_ADDRESS}参数，如：./redis-cli -h 127.0.0.1
redis&gt; ping
PONG
redis&gt; set foo bar
OK
redis&gt; get foo
&quot;bar&quot;
redis&gt; incr mycounter
(integer) 1
redis&gt; incr mycounter
(integer) 2
redis&gt;
</code></pre><p>You can find the list of all the available commands at <a href="http://redis.io/commands" target="_blank" rel="noopener">http://redis.io/commands</a>.</p>
<p>  <strong><em>注意：启动Redis服务器的时候，请务必指定它的配置文件，否则有可能会出现意想不到的情况。</em></strong></p>
<h4 id="为Redis设置登录密码"><a href="#为Redis设置登录密码" class="headerlink" title="为Redis设置登录密码"></a>为Redis设置登录密码</h4><p>  为Redis设置登录密码的方法比较简单，打开<code>${REDIS_HOME}/redis.conf</code>文件，找到<code>requirepass foobared</code>这一行，如下：</p>
<pre><code>################################## SECURITY ###################################

# Require clients to issue AUTH &lt;PASSWORD&gt; before processing any other
# commands.  This might be useful in environments in which you do not trust
# others with access to the host running redis-server.
#
# This should stay commented out for backward compatibility and because most
# people do not need auth (e.g. they run their own servers).
#
# Warning: since Redis is pretty fast an outside user can try up to
# 150k passwords per second against a good box. This means that you should
# use a very strong password otherwise it will be very easy to break.
#
# requirepass foobared
</code></pre><p>将<code>requirepass foobared</code>的注释打开，并把foobared设置成自己的密码即可，如将其设为abc123： </p>
<pre><code>requirepass abc123
</code></pre><p>保存文件，并重启Redis。</p>
<p>在使用客户端登录的时候，将使用如下命令：</p>
<pre><code>$ cd src
$ ./redis-cli -a abc123

或者使用下面的方式更安全
$ cd src
$ ./redis-cli
127.0.0.1:6379&gt; AUTH abc123
OK
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/08/07/redis-install/" data-id="cjmx9poeq001uvt2io2pimsp0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/redis/">redis</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-jvm-note" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/06/jvm-note/" class="article-date">
  <time datetime="2018-04-06T03:29:42.000Z" itemprop="datePublished">2018-04-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/06/jvm-note/">jvm 学习笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>最近在看周志明先生的《深入理解JAVA虚拟机JVM高级特性与最佳实践》，作笔记如下，以便自已复习。文中代码，大部分摘自书中。</p>
<p>JVM的基本结构：类加载子系统、方法区、JAVA堆、JAVA栈、本地方法区、程序计数器、直接内存、垃圾回收系统和执行引擎。</p>
<p>JVM的运行时数据区如下所示：<br><img src="/img/jvm-runtime-data-schema.png" alt="" title="图片来源于网络，仅用于学习使用"></p>
<p>JAVA的NIO库允许程序使用直接内存，从而提高性能，通常直接内存速度会优于堆。读写频繁的场合，可以优先考虑使用。</p>
<p>lambda函数式编程的一个重要优点就是这样的程序天然地适合并行运行，这对JAVA语言在多核时代继续保持主流语言的地位有很大的帮助。</p>
<h3 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h3><ol>
<li>引用计数法：是古老而经典的垃圾收集算法，其核心就是在对象被其他所引用的时候计数器加1,而当引用失效时则减1.但是这种方式有非常严重的问题：无法处理循环引用的情况、还有的就是每次进行加减操作比较浪费系统性能。</li>
<li>标记清除法：分为标记和清除两个阶段，这种方式也有非常大的洞弊端，就是空间碎片问题，垃圾回收后，空间不是连续的。</li>
<li>复制算法：其核心思想就是将内存分为两块，每次只使用其中一块。在回收时，将正在使用的内存中的存留对象复制到未被使用的内存中去，之后清除之前正在使用的内存中的所有对象，反复去交换两个内存的角式。</li>
<li>标记压缩法：是在标记清除法的基础上做了优化，把存活的对象压缩到内存的一端，然后进行垃圾清理（老年代中使用的回收方法）</li>
<li>分代算法：根据对象的特点把内存分成N块，然后根据每个对象的特点使用不同的算法。对于新生代，它的回收频率很高，但是每次回收耗时都很短；而老年代回收频率较低，但是耗时相对较长，所以应该尽量减少老年代的GC。</li>
</ol>
<h3 id="确定对像是否已死的方法"><a href="#确定对像是否已死的方法" class="headerlink" title="确定对像是否已死的方法"></a>确定对像是否已死的方法</h3><ol>
<li>引用计数法；</li>
<li>可达性分析算法GC Root.</li>
</ol>
<h3 id="垃圾回收器"><a href="#垃圾回收器" class="headerlink" title="垃圾回收器"></a>垃圾回收器</h3><ol>
<li>串行回收器： 使用单线程进行垃圾回收的回收器。每次回收时，串行回收器只有一个工作线程，对于并行能力较弱的计算机来说，串行回收器的专注性和独占性往往有更好的性能表现。可以在新生代和老年代使用。<code>-XX:+UseSerialGC</code></li>
<li>并行回收器： 在串行回收器的基础上作了改进，他可以使用多个线程同时进行垃圾回收，对于计算能力强的计算机而言，可以有效的缩短回收所需的实际时间。他只是简单的将串行回收器多线程化，他的回收策略和算法和串行回收器一样。只使用在新生代。<code>--XX:+UseParNewGC</code></li>
<li>ParallelGC： 新生代回收器，使用了复杂算法的收集器，也是多线程独占形式的收集器，它有个特点，就是它非常关注系统的吞吐量。</li>
<li>CMS：全称为<code>Concurrent Mark Sweep</code>，意为并发标记清除，他使用的是标记清除法，主要关注系统停顿时间。<code>-XX:+UseConcMarkSweepGC</code>进行设置，<code>-XX:ConcGCThreads</code>设置并发线程数量。CMS并不是独占的回收器，也就是说CMS回收的过程中，应用程序 仍然可以在不停的工作，不过会有新的垃圾产生。CMS比较耗内存，CMS不会等到应用程序饱和的时候才去回收垃圾，而是在某一个阀值的时候开始回收，可以使用参数指定：<code>-XX:CMSInitiatingOccupancyFraction</code>来指定，默认为68,也就是说当老年代的空间使用率达68%的时候，会执行CMS回收。如果内存不足，收集可能会失败，如果失败了，会启动老年代串行回收器。</li>
<li>G1：<code>Garbage-First</code>是在JDK1.7中提出的垃圾回收器，是为了取代CMS的回收器。它属于分代回收器，并行性和并发性。并行性是G1回收期间可多线程同时工作，而并发性是G1拥有与应用程序交替执行能力，部分工作可与应用程序同时执行，在整个GC期间不会完全阻塞应用程序。它可以工作在新生代和老年代。之前的回收器，或者工作在新生代，或者工作在老年代。G1使用了有益智复制对象的方式，减少空间碎片。</li>
</ol>
<p>将GC的日志输出到文件可以配置JVM启动参数：<code>-Xloggc:/home/hewentian/Document/gc.log</code></p>
<h3 id="class文件格式"><a href="#class文件格式" class="headerlink" title="class文件格式"></a>class文件格式</h3><p>class文件是一组以8位字节码为基础单位的二进制流，各个数据项目严格按照顺序紧凑地排列在class文件之中，中间没有添加任何分隔符，这使得整个class文件中存储的内容几乎全部是程序运行的必要数据，没有空隙存在。当遇到需要占用8位字节以上空间的数据项时，则会按照高位在前的方式分割成若干个8位字节进行存储。</p>
<p>无符号数属于基本的数据类型，以u1, u2, u4, u8来分别代表1，2, 4, 8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串值。</p>
<p>如下图所示：<br><img src="/img/class-file-format.png" alt="" title="图片来源：周志明先生的《深入理解JAVA虚拟机JVM高级特性与最佳实践》"></p>
<h3 id="魔数与class文件的版本"><a href="#魔数与class文件的版本" class="headerlink" title="魔数与class文件的版本"></a>魔数与class文件的版本</h3><p><strong>魔数：</strong> 每个class文件的头4个字节称为魔数(Magic Number)，它的唯一作用是确定这个文件是否为一个能被虚拟机接受的class文件。<br><strong>版本号：</strong> 紧接着魔的4个字节存储的是class文件的版本号：第5和第6个字节是次版本号(Minor Version)，第7和第8个字节是主版本号(Major Version)。只有当前JVM的版本号大于等于这个文件的版本号，该文件才会被JVM加载。</p>
<h3 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h3><p>JVM直接支持（转换时无需显式的转换指令）：</p>
<ol>
<li>int类型到long, float或者double类型；</li>
<li>long类型到float, double类型；</li>
<li>float类型到double类型。</li>
</ol>
<h3 id="类的加载过程"><a href="#类的加载过程" class="headerlink" title="类的加载过程"></a>类的加载过程</h3><p>JVM中类的加载过程：加载、验证、准备、解析、初始化。如果算上：使用和缷载这两个过程，则一共有7个过程。</p>
<p>加载：加载要完成以下三件事：</p>
<ol>
<li>通过一个类的全限定名来获取定义此类的二进制字节流（不一定从文件中读取，可以从网络或数据库中）；</li>
<li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构;</li>
<li>在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。</li>
</ol>
<p>验证：验证是连接阶段的第一步，这一阶段的目的是为了确保class文件的字节流中包含的信息符合当前JVM的要求，并且不会危害JVM自身的安全。<br>准备：正式为类变量分配内存并设置类变量（static修饰）初始值的阶段，通常是该类型的零值；<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> value = <span class="number">123</span>;</span><br></pre></td></tr></table></figure></p>
<p>变量value在准备阶段过后的初始值为0，而不是123。赋值为123在初始化阶段才会执行。</p>
<p>解析：JVM将常量池内的符号引用替换为直接引用的过程；<br>初始化：执行类构造器的过程，设置实例变量的初始值。</p>
<p>其中，加载、验证、准备、初始化和缷载这5个阶段的顺序是确定的。如下图所示：<br><img src="/img/class-loading.png" alt="" title="图片来源：周志明先生的《深入理解JAVA虚拟机JVM高级特性与最佳实践》"></p>
<h3 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h3><p>从JAVA开发人员的角度来看，绝大部分JAVA程序都会使用到以下3种系统提供的类加载器：</p>
<ol>
<li>启动类加载器(Bootstrap ClassLoader)：这个类加载器负责将存放在<code>&lt;JAVA_HOME&gt;\lib</code>目录中的，或者被<code>-Xbootclasspath</code>参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被JAVA程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器，那么使用null代替即可。</li>
<li>扩展类加载器(Extension ClassLoader)：这个加载器由<code>sum.misc.Launcher$ExtClassLoader</code>实现，它负责加载<code>&lt;JAVA_HOME&gt;\lib\ext</code>目录中的，或者被<code>java.ext.dirs</code>系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。</li>
<li>应用程序类加载器(Application ClassLoader)：这个类加载器由<code>sum.misc.Launcher$AppClassLoader</code>实现。由于这个类加载器是<code>ClassLoader中的getSystemClassLoader()</code>方法的返回值，所以一般也称它为系统类加载器。它负责加载用户类路径(ClassPath)上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自已的类加载器，一般情况下这个就是程序中默认的类加载器。</li>
</ol>
<p>我们的应用程序都是由这3种类加载器互相配合进行加载的，如果有必要，还可以加入自已定义的类加载器。这些类加载器之间的关系一般如下图所示，这种层次关系，称为类加载器的双亲委派模型。<br><img src="/img/class-loader-mode.png" alt="" title="图片来源：周志明先生的《深入理解JAVA虚拟机JVM高级特性与最佳实践》"></p>
<h3 id="当泛型遇上重载"><a href="#当泛型遇上重载" class="headerlink" title="当泛型遇上重载"></a>当泛型遇上重载</h3><p>下面的代码是不能通过编译的，因为参数<code>List&lt;String&gt;</code>和<code>List&lt;Integer&gt;</code>编译之后都被擦除了，变成了一样的<code>List&lt;E&gt;</code>，擦除动作导致这两种方法的特征签名变得一模一样。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">method</span><span class="params">(List&lt;String&gt; list)</span> </span>&#123;</span><br><span class="line">	System.out.println(<span class="string">"invoke method(List&lt;String&gt; list)"</span>);</span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">method</span><span class="params">(List&lt;Integer&gt; list)</span> </span>&#123;</span><br><span class="line">	System.out.println(<span class="string">"invoke method(List&lt;Integer&gt; list)"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>如果真是要重载，可以适当修改上述代码，只要增加返回值即可，它也只能在JDK1.6上可以编译通过。在JDK1.8也是无法编译通过的。如下所示：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">method</span><span class="params">(List&lt;String&gt; list)</span> </span>&#123;</span><br><span class="line">	System.out.println(<span class="string">"invoke method(List&lt;String&gt; list)"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">method</span><span class="params">(List&lt;Integer&gt; list)</span> </span>&#123;</span><br><span class="line">	System.out.println(<span class="string">"invoke method(List&lt;Integer&gt; list)"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="自动装箱的陷阱"><a href="#自动装箱的陷阱" class="headerlink" title="自动装箱的陷阱"></a>自动装箱的陷阱</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	Integer a = <span class="number">1</span>;</span><br><span class="line">	Integer b = <span class="number">2</span>;</span><br><span class="line">	Integer c = <span class="number">3</span>;</span><br><span class="line">	Integer d = <span class="number">3</span>;</span><br><span class="line">	Integer e = <span class="number">321</span>;</span><br><span class="line">	Integer f = <span class="number">321</span>;</span><br><span class="line">	Long g = <span class="number">3L</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 在 JDK1.8 中的结果如下</span></span><br><span class="line">	System.out.println(c == d);		<span class="comment">// true, [-127, 128]之间的Integer数字会被缓存</span></span><br><span class="line">	System.out.println(e == f);		<span class="comment">// false</span></span><br><span class="line">	System.out.println(c == (a + b));	<span class="comment">// true</span></span><br><span class="line">	System.out.println(c.equals(a + b));	<span class="comment">// true</span></span><br><span class="line">	System.out.println(g == (a + b));	<span class="comment">// true</span></span><br><span class="line">	System.out.println(g.equals(a + b));	<span class="comment">// false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="final语言校验"><a href="#final语言校验" class="headerlink" title="final语言校验"></a>final语言校验</h3><p>下面这两段代码编译出来的class文件是一样的，没有任何区别。只是在编写程序的时候会受到final的约束。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 方法一：带有final修饰</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">final</span> <span class="keyword">int</span> var = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">// do something</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法二：没有final修饰</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">int</span> var = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">// do something</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="解释器与编译器"><a href="#解释器与编译器" class="headerlink" title="解释器与编译器"></a>解释器与编译器</h3><p>尽管不是所有的JVM都采用解释器与编译器并存的架构，但许多主流的商用JVM，如HotSpot、J9等，都同时包含解释器与编译器。<strong>但是，三大商用JVM之一的JRockit是个例外，它内部没有解释器。</strong>解释器与编译器两者各有优势：当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即执行。在程序运行后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码之后，可以获取更高的执行效率。当程序运行环境中内存资源限制较大（如部分嵌入式系统中），可以使用解释执行节约内存，反之可以使用编译执行来提升效率。在整个JVM执行架构中，解释器与编译器经常配合工作，如下图。<br><img src="/img/compiler-and-interpreter.png" alt="" title="图片来源：周志明先生的《深入理解JAVA虚拟机JVM高级特性与最佳实践》"></p>
<h3 id="程序编译与代码优化"><a href="#程序编译与代码优化" class="headerlink" title="程序编译与代码优化"></a>程序编译与代码优化</h3><p>从sum javac的代码来看，编译过程大致可以分成3个过程：</p>
<ol>
<li>解析与填充符号表的过程(Parse and Enter);</li>
<li>插入式注解处理器的注解处理过程(Annotation Processing);</li>
<li>分析与字节码生成的过程(Analyse and Generate)。</li>
</ol>
<h3 id="编译对象与触发条件"><a href="#编译对象与触发条件" class="headerlink" title="编译对象与触发条件"></a>编译对象与触发条件</h3><p>在程序运行的过程中会被即时编译器JIT编译的“热点代码”有两类：</p>
<ol>
<li>被多次调用的方法；</li>
<li>被多次执行的循环体。</li>
</ol>
<p>判断一段代码是不是热点代码，是不是需要触发即时编译，这样的行为称为热点探测(Hot Spot Detection)，其实进行热点探测并不一定要知道方法具体被调用了多少次，目前主要的热点探测判定方法有两种，分别如下：</p>
<ul>
<li>基于采样的热点探测(Sample Based Hot Spot Detection)：采用这种方法的JVM会周期性地检查各个线程的栈顶，如果发现某个（或某些）方法经常出现在栈顶，那这个方法就是“热点方法”。基于采样的热点探测的好处是实现简单、高效，还可以很容易地获取方法调用关系（将调用堆栈展开即可），缺点是很难精确地确认一个方法的热度，容易因为受到线程阻塞或别的外界因素的影响而扰乱热点探测。</li>
<li>基于计数器的热点探测(Counter Based Hot Spot Detection)：采用这种方法的JVM会为每个方法（甚至是代码块）建立计数器，统计方法的执行次数，如果执行次数超过一定的阈值就认为它是“热点方法”。这种统计方法实现起来麻烦一些，需要为每个方法建立并维护计数器，而且不能直接获取到方法的调用关系，但是它的统计结果相对来说更加精确和严谨。</li>
</ul>
<p>在HotSpot虚拟机中使用的是第二种–基于计数器的热点探测方法，因此它为每个方法准备了两类计数器：方法调用计数器(Invocation Counter)和回边计数器(Back Edge Counter)。</p>
<p>在确定虚拟机运行参数的前提下，这两个计数器都有一个确定的阈值，当计数器超过阈值溢出了，就会触发JIT编译。</p>
<p>我们首先来看看方法调用计数器，顾名思义，这个计数器就用于统计方法被调用的次数，它的默认阈值在Client模式下是1500次，在Server模式下是10000次，这个阈值可以通过JVM参数<code>-XX:CompileThreshold</code>来人为设定。</p>
<p>下面我们再来看看回边计数器。<strong>什么是回边？ 在字节码遇到控制流向后跳转的指令称为回边（Back Edge）。</strong>回边计数器是用来统计一个方法中循环体代码执行的次数，回边计数器的阈值可以通过参数<code>-XX：OnStackReplacePercentage</code>来调整。</p>
<p>虚拟机运行在Client模式下，回边计数器阈值计算公式为：<br>方法调用计数器阈值(CompileThreshold) x OSR比率(OnStackReplacePercentage) / 100<br>其中OnStackReplacePercentage默认值为933，如果都取默认值，那Client模式虚拟机的回边计数器的阈值为13995.</p>
<p>虚拟机运行在Server模式下，回边计数器阈值的计算公式为：<br>方法调用计数器阈值(CompileThreshold) x (OSR比率(OnStackReplacePercentage) - 解释器监控比率(InterpreterProfilePercentage) / 100<br>其中OnStackReplacePercentage默认值为140，InterpreterProfilePercentage默认值为33。<br>如果都取默认值，那Server模式虚拟机回边计数器的阑值为10700。</p>
<p>回边计数器与方法调用计数器不同的是，回边计数器没有热度衰减，因此这个计数器统计的就是循环执行的绝对次数。</p>
<p>参见下图：<br><img src="/img/method-invoke-trigger-jit.png" alt="" title="图片来源：周志明先生的《深入理解JAVA虚拟机JVM高级特性与最佳实践》"></p>
<h3 id="程序延时一定时间"><a href="#程序延时一定时间" class="headerlink" title="程序延时一定时间"></a>程序延时一定时间</h3><p>像下面的空循环经JIT编译器优化后，会被消除掉，以前很多入门教程把空循环当做程序延时的手段来介绍，其实是错误的。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++)</span><br><span class="line">	;</span><br></pre></td></tr></table></figure></p>
<p>要延时应该使用下面的方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">	Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">	e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>不使用的对象应手动设为null，不过，赋值为null的操作在经过JIT编译优化后就会被消除掉，这时候将变量设置为null就是没有意义的。</p>
<h3 id="线程、主内存、工作内存、处理器、关系图"><a href="#线程、主内存、工作内存、处理器、关系图" class="headerlink" title="线程、主内存、工作内存、处理器、关系图"></a>线程、主内存、工作内存、处理器、关系图</h3><p><img src="/img/cpu-thread-memory.png" alt="" title="图片来源：周志明先生的《深入理解JAVA虚拟机JVM高级特性与最佳实践》"></p>
<h3 id="内存间交互操作"><a href="#内存间交互操作" class="headerlink" title="内存间交互操作"></a>内存间交互操作</h3><p>关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存复制到工作内存、如何从工作内存同步回主内存之类的实现细节，JAVA内存模型中定义了以下8种操作来完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的（对于double和long类型的变量来说，load、store、read和write操作在某些平台上允许有例外）。</p>
<ul>
<li>lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态；</li>
<li>unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定；</li>
<li>read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用；</li>
<li>load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中；</li>
<li>use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作；</li>
<li>assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作；</li>
<li>store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用；</li>
<li>write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。</li>
</ul>
<h3 id="volatile变量的使用场景"><a href="#volatile变量的使用场景" class="headerlink" title="volatile变量的使用场景"></a>volatile变量的使用场景</h3><p>由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然要通过加锁（使用synchronized或java.util.concurrent中的原子类）来保证原子性。</p>
<ol>
<li>运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值；</li>
<li>变量不需要与其他的状态变量共同参与不变约束。</li>
</ol>
<p>像下面的代码就很适合使用volatile变量来控制并发，当shutdown方法被调用时，能保证所有线程中执行的doWork()方法都立即停下来。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="keyword">boolean</span> shutdownRequest;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shutdown</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	shutdownRequest = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(!shutdownRequest) &#123;</span><br><span class="line">	<span class="comment">// do stuff</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="线程状态转换"><a href="#线程状态转换" class="headerlink" title="线程状态转换"></a>线程状态转换</h3><p>Java语言定义了5种线程状态，在任意一个时间点，一个线程只能有且只有其中的一种状态，这5种状态分别如下：</p>
<ul>
<li>新建（New）：创建后尚未启动的线程处于这种状态；</li>
<li>运行（Runnable）：Runnable包括了操作系统线程状态中的Running和Ready，也就是处于此状态的线程有可能正在执行，也有可能正在等待着CPU为它分配执行时间；</li>
<li>无限期等待（Waiting）：处于这种状态的线程不会被分配CPU执行时间，它们要等待被其他线程显式地唤醒。以下方法会让线程陷入无限期的等待状态：<ul>
<li>没有设置Timeout参数的Object.wait()方法；</li>
<li>没有设置Timeout参数的Thread.join()方法；</li>
<li>LockSupport.park()方法；</li>
</ul>
</li>
<li>限期等待（Timed Waiting）：处于这种状态的线程也不会被分配CPU执行时间，不过无须等待被其他线程显式地唤醒，在一定的时间之后它们会由系统自动唤醒。以下方法会让线程进入限期等待状态：<ul>
<li>Thread.sleep()方法；</li>
<li>设置了Timeout参数的Object.wait()方法；</li>
<li>设置了Timeout参数的Thread.join()方法；</li>
<li>LockSupport.parkNanos()方法；</li>
<li>LockSupport.parkUntil()方法；</li>
</ul>
</li>
<li>阻塞（Blocked）：线程被阻塞了，“阻塞状态”与“等待状态”的区别是：“阻塞状态”在等待着获取到一个排他锁，这个事件将在另外一个线程放弃这个锁的时候发生；而“等待状态”则是在等待一段时间，或者唤醒动作的发生。在程序等待进入同步区域的时候，线程将进入这种状态。</li>
<li>结束（Terminated）：已终止线程的线程状态，线程已经结束执行。</li>
</ul>
<p>上述5种状态在遇到特定事件发生的时候会互相转换，它们的转换关系如下图所示：<br><img src="/img/thread-state-transform.png" alt="" title="图片来源：周志明先生的《深入理解JAVA虚拟机JVM高级特性与最佳实践》"></p>
<p><strong>声明：</strong>图片来源于网络，仅用于学习使用。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/04/06/jvm-note/" data-id="cjmx9pod90011vt2i2rrcu8xu" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/jvm/">jvm</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-mongo-note" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/07/mongo-note/" class="article-date">
  <time datetime="2018-03-07T06:39:42.000Z" itemprop="datePublished">2018-03-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/db/">db</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/07/mongo-note/">mongo 学习笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="导出、导入数据库"><a href="#导出、导入数据库" class="headerlink" title="导出、导入数据库"></a>导出、导入数据库</h3><h4 id="我们使用mongoexport来导出指定的collection"><a href="#我们使用mongoexport来导出指定的collection" class="headerlink" title="我们使用mongoexport来导出指定的collection"></a>我们使用<code>mongoexport</code>来导出指定的<code>collection</code></h4><p>该命令位于<code>{MONGO_HOME}/bin/</code>目录下，可以把一个<code>collection</code>导出成JSON或CSV格式的文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">语法：</span><br><span class="line">$ mongoexport -h &#123;SERVER_ADDRESS&#125; --port &#123;SERVER_PORT&#125; -u &#123;USER_NAME&#125; -p &#123;PASSWORD&#125; --authenticationDatabase &#123;AUTH_DB&#125; -d &#123;DB_NAME&#125; -c &#123;COLLECTION_NAME&#125; -o &#123;EXPORT_FILE_PATH&#125; --<span class="built_in">type</span> json/csv -f fields</span><br><span class="line"></span><br><span class="line">参数说明：</span><br><span class="line"></span><br><span class="line">	-h: MONGODB服务器的地址</span><br><span class="line">	--port: MONGODB服务器的端口</span><br><span class="line">	-u: 用户名</span><br><span class="line">	-p: 密码</span><br><span class="line">	--authenticationDatabase: 验证数据库</span><br><span class="line">	-d: 数据库名</span><br><span class="line">	-c: collection名</span><br><span class="line">	-o: 输出的文件名</span><br><span class="line">	--<span class="built_in">type</span>: 输出的格式，默认为json</span><br><span class="line">	-f: 输出的字段，如果-<span class="built_in">type</span>为csv，则需要加上-f <span class="string">"字段名"</span></span><br><span class="line"></span><br><span class="line">示例：</span><br><span class="line">$ mongoexport -h 127.0.0.1 --port 27017 -u bfg_user -p a12345678 --authenticationDatabase admin -d bfg -c user -o /home/hewentian/ProjectD/db/user.json</span><br><span class="line">$ mongoexport -h 127.0.0.1 --port 27017 -u bfg_user -p a12345678 --authenticationDatabase admin -d bfg -c user -o /home/hewentian/ProjectD/db/user.json --<span class="built_in">type</span> json -f  <span class="string">"_id,name"</span></span><br><span class="line">$ mongoexport -h 127.0.0.1 --port 27017 -u bfg_user -p a12345678 --authenticationDatabase admin -d bfg -c user -o /home/hewentian/ProjectD/db/user.csv --<span class="built_in">type</span> csv -f  <span class="string">"_id,name"</span></span><br></pre></td></tr></table></figure></p>
<h4 id="我们使用mongoimport来导入指定的collection"><a href="#我们使用mongoimport来导入指定的collection" class="headerlink" title="我们使用mongoimport来导入指定的collection"></a>我们使用<code>mongoimport</code>来导入指定的<code>collection</code></h4><p>该命令位于<code>{MONGO_HOME}/bin/</code>目录下，可以把一个json/csv文件导入到指定的<code>collection</code>中<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">语法：</span><br><span class="line">$ mongoimport -h &#123;SERVER_ADDRESS&#125; --port &#123;SERVER_PORT&#125; -u &#123;USER_NAME&#125; -p &#123;PASSWORD&#125; --authenticationDatabase &#123;AUTH_DB&#125; -d &#123;DB_NAME&#125; -c &#123;COLLECTION_NAME&#125; --file &#123;IMPORT_FILE_PATH&#125; --headerline --<span class="built_in">type</span> json/csv -f fields</span><br><span class="line"></span><br><span class="line">参数说明：</span><br><span class="line"></span><br><span class="line">	-h: MONGODB服务器的地址</span><br><span class="line">	--port: MONGODB服务器的端口</span><br><span class="line">	-u: 用户名</span><br><span class="line">	-p: 密码</span><br><span class="line">	--authenticationDatabase: 验证数据库</span><br><span class="line">	-d: 数据库名</span><br><span class="line">	-c: collection名</span><br><span class="line">	--file: 要导入的文件</span><br><span class="line">	--<span class="built_in">type</span>: input format to import: json, csv, or tsv (defaults to <span class="string">'json'</span>) (default: json)</span><br><span class="line">	--headerline: use first line <span class="keyword">in</span> input <span class="built_in">source</span> as the field list (CSV and TSV only)</span><br><span class="line">	-f: 导入的字段名，CSV或TSV的时候可用</span><br><span class="line"> </span><br><span class="line">示例：</span><br><span class="line">$ mongoimport -h 127.0.0.1 --port 27017 -u bfg_user -p a12345678 --authenticationDatabase admin -d bfg -c user --file /home/hewentian/ProjectD/db/user.json</span><br><span class="line"></span><br><span class="line">注意：--headerline 和 -f 不能同时使用</span><br><span class="line"></span><br><span class="line">	--headerline: 使用CSV文件中首列指定的列名作为导入的name</span><br><span class="line">	-f: 会将CSV文件的所有列，作为数据进行导入，包括第一列的列名（如果文件中有指定列名）</span><br><span class="line"></span><br><span class="line">$ mongoimport -h 127.0.0.1 --port 27017 -u bfg_user -p a12345678 --authenticationDatabase admin -d bfg -c user --file /home/hewentian/ProjectD/db/user.csv --<span class="built_in">type</span> csv --headerline</span><br><span class="line">$ mongoimport -h 127.0.0.1 --port 27017 -u bfg_user -p a12345678 --authenticationDatabase admin -d bfg -c user --file /home/hewentian/ProjectD/db/user.csv --<span class="built_in">type</span> csv -f <span class="string">"_id,name,age"</span></span><br></pre></td></tr></table></figure></p>
<h4 id="我们使用mongodump来导出指定的database"><a href="#我们使用mongodump来导出指定的database" class="headerlink" title="我们使用mongodump来导出指定的database"></a>我们使用<code>mongodump</code>来导出指定的<code>database</code></h4><p>该命令位于<code>{MONGO_HOME}/bin/</code>目录下，可以把一个<code>database</code>导出成指定目录下的JSON、BSON的文件集<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">语法：</span><br><span class="line">$ mongodump -h &#123;SERVER_ADDRESS&#125; --port &#123;SERVER_PORT&#125; -u &#123;USER_NAME&#125; -p &#123;PASSWORD&#125; --authenticationDatabase &#123;AUTH_DB&#125; -d &#123;DB_NAME&#125; -o &#123;DUMP_FILE_PATH&#125;</span><br><span class="line"></span><br><span class="line">参数说明：</span><br><span class="line"></span><br><span class="line">	-h: MONGODB服务器的地址</span><br><span class="line">	--port: MONGODB服务器的端口</span><br><span class="line">	-u: 用户名</span><br><span class="line">	-p: 密码</span><br><span class="line">	--authenticationDatabase: 验证数据库</span><br><span class="line">	-d: 数据库名</span><br><span class="line">	-o: 输出的文件路径，要事先创建该目录，在该目录下会自动创建要导出的数据库作为子目录</span><br><span class="line"></span><br><span class="line">示例：</span><br><span class="line">$ mongodump -h 127.0.0.1 --port 27017 -u bfg_user -p a12345678 --authenticationDatabase admin -d bfg -o /home/hewentian/ProjectD/db/</span><br></pre></td></tr></table></figure></p>
<h4 id="我们使用mongorestore来恢复指定的database"><a href="#我们使用mongorestore来恢复指定的database" class="headerlink" title="我们使用mongorestore来恢复指定的database"></a>我们使用<code>mongorestore</code>来恢复指定的<code>database</code></h4><p>该命令位于<code>{MONGO_HOME}/bin/</code>目录下，可以把指定目录下的JSON、BSON的文件集恢复成<code>database</code><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">语法：</span><br><span class="line">$ mongorestore -h &#123;SERVER_ADDRESS&#125; --port &#123;SERVER_PORT&#125; -u &#123;USER_NAME&#125; -p &#123;PASSWORD&#125; --authenticationDatabase &#123;AUTH_DB&#125; -d &#123;DB_NAME&#125; --dir &#123;RESTORE_FILE_PATH&#125;</span><br><span class="line"></span><br><span class="line">参数说明：</span><br><span class="line"></span><br><span class="line">	-h: MONGODB服务器的地址</span><br><span class="line">	--port: MONGODB服务器的端口</span><br><span class="line">	-u: 用户名</span><br><span class="line">	-p: 密码</span><br><span class="line">	--authenticationDatabase: 验证数据库</span><br><span class="line">	-d: 数据库名</span><br><span class="line">	--dir: 要恢复的数据库的位置，注意与上面备份的 -o 不同，这里要指定到数据库的目录</span><br><span class="line"></span><br><span class="line">示例：</span><br><span class="line">$ mongorestore -h 127.0.0.1 --port 27017 -u bfg_user -p a12345678 --authenticationDatabase admin -d bfg --dir /home/hewentian/ProjectD/db/bfg/</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/03/07/mongo-note/" data-id="cjmx9podx001evt2iq4iynk51" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mongo/">mongo</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/bigdata/">bigdata</a><span class="category-list-count">17</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/db/">db</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a><span class="category-list-count">7</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a><span class="archive-list-count">4</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/10/05/jenkins-install/">jenkins 学习笔记</a>
          </li>
        
          <li>
            <a href="/2018/10/02/ELK-install/">ELK 日志系统的搭建</a>
          </li>
        
          <li>
            <a href="/2018/09/18/elasticsearch-note/">elasticsearch 学习笔记</a>
          </li>
        
          <li>
            <a href="/2018/09/17/elasticsearch-cluster/">elasticsearch 集群的搭建</a>
          </li>
        
          <li>
            <a href="/2018/09/16/elasticsearch-install/">elasticsearch 单节点安装</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">link</h3>
    <div class="widget">
      <li><a href="https://github.com/hewentian" title="Tim Ho's Blog">我的github</a></li>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Tim Ho<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives/" class="mobile-nav-link">Archives</a>
  
    <a href="/categories/" class="mobile-nav-link">Categories</a>
  
    <a href="/tags/" class="mobile-nav-link">Tags</a>
  
    <a href="/about/" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>